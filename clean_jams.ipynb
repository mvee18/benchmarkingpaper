{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from utils.ncbi.jams_convert import convert_jams_to_taxid, generate_names_df, names_db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\"LKT__s__Anaerobutyricum_hallii\": \"LKT__s__Eubacterium_hallii\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update replacement dict for JAMS.\n",
    "\n",
    "from tkinter.font import names\n",
    "\n",
    "\n",
    "camisim_replacement_dict = {\n",
    "    \"Acetivibrio_thermocellus\": \"Ruminiclostridium_thermocellum\", \n",
    "    \"Thermoclostridium_stercorarium\": \"Ruminiclostridium_stercorarium\",\n",
    "}\n",
    "\n",
    "def clean_jams(input_file: str, rank: str = \"Genus\", input_type=\"csv\", replacement=None):\n",
    "    \"\"\"\n",
    "    This function cleans the output from JAMSalpha in the tourlousse dataset. From now on, use the JAMSbeta function.\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = os.path.dirname(input_file)\n",
    "    file_name = os.path.basename(input_file).split(\".\")[0]\n",
    "    csv_path = os.path.join(output_dir, f\"{file_name}_{rank.lower()}_relabund.csv\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    if input_type == \"csv\":\n",
    "        df = pd.read_csv(input_file, index_col=0)\n",
    "    elif input_type == \"excel\":\n",
    "        df = pd.read_excel(input_file, index_col=0)\n",
    "    else:\n",
    "        raise Exception(\"Input type not recognized.\")\n",
    "    \n",
    "    df[\"RA\"] = df[\"NumBases\"] / df[\"NumBases\"].sum()\n",
    "    # display(df.head())\n",
    "    species_df = df[[\"Species\", \"RA\"]].groupby(\"Species\").sum()\n",
    "    species_df.sort_values(\"RA\", ascending=False, inplace=True)\n",
    "\n",
    "    # We need to remove g__ and s__ from the index names\n",
    "    # genus_df.index = genus_df.index.str.replace(\"g__\", \"\")\n",
    "    species_df.index = species_df.index.str.replace(\"s__\", \"\")\n",
    "\n",
    "    # We need to replace the names of the species that have changed to the old ones.\n",
    "    if replacement is not None:\n",
    "        species_names = species_df.index.tolist()\n",
    "        for i, name in enumerate(species_names):\n",
    "            if name in replacement:\n",
    "                species_names[i] = replacement[name]\n",
    "    \n",
    "        species_df.index = species_names\n",
    "\n",
    "    if rank == \"Genus\":\n",
    "        # We need to split the species names into genus and species on the _ character.\n",
    "        species_names = species_df.index.to_list()\n",
    "        genus_names = [x.split(\"_\")[0] for x in species_names]\n",
    "\n",
    "        species_df[\"Genus\"] = genus_names\n",
    "\n",
    "        genus_df = species_df[[\"Genus\", \"RA\"]].groupby(\"Genus\").sum()\n",
    "\n",
    "        genus_df.sort_values(\"RA\", ascending=False, inplace=True)\n",
    "\n",
    "        genus_df.to_csv(csv_path)\n",
    "\n",
    "    names_df = generate_names_df(names_db_path, load_pickle=True)\n",
    "\n",
    "    annotated, unannotated = convert_jams_to_taxid(csv_path, names_df)\n",
    "    annotated.to_csv(csv_path.replace(\".csv\", \"_annotated.csv\"), index_label=rank)\n",
    "\n",
    "clean_jams(input_file = \"pipelines/bmock12/jams/s1.csv\", rank = \"Species\", input_type = \"csv\", replacement = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jams_beta(input_file: str, rank=\"genus\", output_dir=\"\"):\n",
    "    \"\"\"Clean JAMS output excel file and save them in the preferred format. \n",
    "    It will generate a separate file for each sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dir : str\n",
    "        Path to directory containing JAMS output files.\n",
    "    rank : str\n",
    "        Taxonomic rank.\n",
    "    output_dir : str\n",
    "        Path to directory where output files will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_excel(input_file, index_col=0, sheet_name=1)\n",
    "    # Make everything into relative abundances\n",
    "    df = df / df.sum(axis=0)\n",
    "    # Convert PPM to percentage.\n",
    "    # df = df / 10000\n",
    "\n",
    "\n",
    "    # We need to find anything with s__ or g__ in the row.names.\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Replace from the replacement dictionary.\n",
    "    df[\"row.names\"] = df[\"row.names\"].replace(replacement_dict)\n",
    "    df.to_csv(\"test.csv\")\n",
    "\n",
    "    # If s__ is in the name, we need to get the genus name.\n",
    "    index_names = []\n",
    "    if rank == \"genus\":\n",
    "        df = df.where(df[\"row.names\"].str.contains(\"g__|s__\")).dropna()\n",
    "        lkt = df[\"row.names\"].to_list()\n",
    "        for i in lkt:\n",
    "            if \"s__\" in i:\n",
    "                index_names.append(i.split(\"s__\")[1].split(\"_\")[0])\n",
    "            else:\n",
    "                index_names.append(i.split(\"g__\")[1].split(\"_\")[0])\n",
    "\n",
    "    elif rank == \"species\":\n",
    "        df = df.where(df[\"row.names\"].str.contains(\"s__\")).dropna()\n",
    "        lkt = df[\"row.names\"].to_list()\n",
    "        for i in lkt:\n",
    "            index_names.append(i.split(\"s__\")[1])\n",
    "            \n",
    "        index_names = [i.replace(\"_\", \" \") for i in index_names]\n",
    "\n",
    "\n",
    "    df.index = index_names\n",
    "    df.drop(columns=[\"row.names\"], inplace=True)\n",
    "\n",
    "    # Sum all of the rows with the same index name.\n",
    "    df = df.groupby(df.index).sum()\n",
    "\n",
    "    # Save each column as a separate file.\n",
    "    if output_dir is not None:\n",
    "        for col in df.columns:\n",
    "            df[col].to_csv(os.path.join(output_dir, f\"{col}_{rank}_relabund.csv\"), index_label=f\"{rank}\")\n",
    "\n",
    "amos_path = \"/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/hilo/jams/beta_output/hilo_Relabund_PPM.xlsx\"\n",
    "\n",
    "clean_jams_beta(amos_path, rank=\"genus\", output_dir=\"pipelines/amos/hilo/jams\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
