{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_palette = sns.color_palette(as_cmap=True)\n",
    "\n",
    "color_palette = {\n",
    "    \"Expected\": cb_palette[0], \n",
    "    \"expected\": cb_palette[0], \n",
    "    \"woltka\": cb_palette[1], \n",
    "    \"wol\": cb_palette[1], \n",
    "    \"jams\": cb_palette[2], \n",
    "    \"wgsa\": cb_palette[3], \n",
    "    \"wgsa2\": cb_palette[3], \n",
    "    \"biobakery3\": cb_palette[4], \n",
    "    \"bio3\": cb_palette[4], \n",
    "    \"biobakery4\": cb_palette[5], \n",
    "    \"bio4\": cb_palette[5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(\"../../pipelines/\")\n",
    "# threshold = 0.0\n",
    "\n",
    "# First, we load the data from the CSV file.\n",
    "def find_stats_files(rank: str, threshold: bool):\n",
    "    for root, dirs, files in os.walk(project_root):\n",
    "        for file in files:\n",
    "            # print(file)\n",
    "            if f\"all_stats_replicates_{rank}\" in file and file.endswith('.csv'):\n",
    "                stats_path = os.path.join(root, file)\n",
    "\n",
    "                df = pd.read_csv(stats_path)\n",
    "\n",
    "                if threshold:\n",
    "                    # Add the threshold to the dataframe\n",
    "                    threshold = file.split(\"_\")[0]\n",
    "                    if threshold == \"all\":\n",
    "                        continue\n",
    "                    else:   \n",
    "                        df[\"threshold\"] = threshold\n",
    "                \n",
    "                yield stats_path, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stats(rank: str, threshold_files: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        rank: str\n",
    "            The rank to combine the stats for.\n",
    "        threshold_files: bool\n",
    "            Whether the files are thresholded or not.\n",
    "    Returns:\n",
    "        df: pd.DataFrame\n",
    "            The combined dataframe.\n",
    "\n",
    "    Combines the stats from all the different pipelines into one dataframe.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for path, df in find_stats_files(rank, threshold_files):\n",
    "        df[\"Source\"] = path.split(\"/\")[-2]\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catplot(df: pd.DataFrame, id_var: str, src: str, plot_type: str, pdf_output: PdfPages, title: str):\n",
    "    melted = df.melt(id_vars=[\"SampleID\", id_var, \"Source\"], var_name=\"Metric\", value_name=\"Value\").dropna()\n",
    "    # Cast value column to float\n",
    "    melted[\"Value\"] = melted[\"Value\"].astype(float)\n",
    "\n",
    "    ax = sns.catplot(data=melted, x=id_var, y=\"Value\", col=\"Metric\", col_wrap=3, kind=plot_type, sharey=False, palette=color_palette)\n",
    "    ax.fig.suptitle(title, y=1.05)\n",
    "\n",
    "    pdf_output.savefig(ax.figure, bbox_inches='tight', dpi=300)\n",
    "    plt.close(ax.figure)\n",
    "\n",
    "def plot_stats(df: pd.DataFrame, output_pdf: str):\n",
    "    pdf_output = PdfPages(output_pdf)\n",
    "    # display(df.head(30))\n",
    "    for th, th_df in df.groupby(\"threshold\"):\n",
    "        for src, df in th_df.groupby(\"Source\"):\n",
    "            title = f'Summary of Statistics for {src} at {th} Threshold'\n",
    "            if src == \"bmock12\" or src == \"camisimGI\":\n",
    "                make_catplot(df, \"Pipeline\", src, \"bar\", pdf_output, title)\n",
    "\n",
    "            else:\n",
    "                no_average = df.loc[df['SampleID'] != 'Average']\n",
    "                make_catplot(no_average, \"Pipeline\", src, \"box\", pdf_output, title)\n",
    "\n",
    "    pdf_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_combined_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # If the Pipeline value is empty, then replace it with the value in \"Source/Pipeline\".\n",
    "    df.loc[df[\"Pipeline\"].isna(), \"Pipeline\"] = df.loc[df[\"Pipeline\"].isna(), \"Source/Pipeline\"]\n",
    "\n",
    "    # Drop rows where the SampleID is \"Average\".\n",
    "    df = df.loc[df[\"SampleID\"] != \"Average\"]\n",
    "\n",
    "    # Drop the \"Source/Pipeline\" column.\n",
    "    df = df.drop(columns=[\"Source/Pipeline\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_stats(combine_stats(\"genus\"), \"stats_summary_genus.pdf\")\n",
    "\n",
    "combined_df = cleanup_combined_df(combine_stats(\"genus\", True))\n",
    "# combined_df.to_csv(\"all_stats_species.csv\", index=False)\n",
    "\n",
    "plot_stats(combined_df, \"stats_summary_genus.pdf\")\n",
    "# display(combined_df.head(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
