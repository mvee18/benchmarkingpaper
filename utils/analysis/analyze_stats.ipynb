{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_palette = sns.color_palette(as_cmap=True)\n",
    "\n",
    "color_palette = {\n",
    "    \"Expected\": cb_palette[0], \n",
    "    \"expected\": cb_palette[0], \n",
    "    \"woltka\": cb_palette[1], \n",
    "    \"wol\": cb_palette[1], \n",
    "    \"jams\": cb_palette[2], \n",
    "    \"wgsa\": cb_palette[3], \n",
    "    \"wgsa2\": cb_palette[3], \n",
    "    \"biobakery3\": cb_palette[4], \n",
    "    \"bio3\": cb_palette[4], \n",
    "    \"biobakery4\": cb_palette[5], \n",
    "    \"bio4\": cb_palette[5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(\"../../pipelines/\")\n",
    "threshold = 0.0\n",
    "\n",
    "# First, we load the data from the CSV file.\n",
    "def find_stats_files(rank: str):\n",
    "    for root, dirs, files in os.walk(project_root):\n",
    "        for file in files:\n",
    "            # print(file)\n",
    "            if f\"all_stats_replicates_{rank}\" in file and file.endswith('.csv'):\n",
    "                stats_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(stats_path)\n",
    "                yield stats_path, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stats(rank: str):\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for path, df in find_stats_files(rank):\n",
    "        df[\"Source\"] = path.split(\"/\")[-2]\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catplot(df: pd.DataFrame, id_var: str, src: str, plot_type: str, pdf_output: PdfPages):\n",
    "    melted = df.melt(id_vars=[\"SampleID\", id_var, \"Source\"], var_name=\"Metric\", value_name=\"Value\").dropna()\n",
    "\n",
    "    ax = sns.catplot(data=melted, x=id_var, y=\"Value\", col=\"Metric\", col_wrap=3, kind=plot_type, sharey=False, palette=color_palette)\n",
    "    ax.fig.suptitle(f'Summary of Statistics for {src}', y=1.05)\n",
    "\n",
    "    pdf_output.savefig(ax.figure, bbox_inches='tight', dpi=300)\n",
    "    plt.close(ax.figure)\n",
    "\n",
    "def plot_stats(df: pd.DataFrame, output_pdf: str):\n",
    "    pdf_output = PdfPages(output_pdf)\n",
    "    # display(df.head(30))\n",
    "    for src, df in df.groupby(\"Source\"):\n",
    "        if src == \"bmock12\" or src == \"camisimGI\":\n",
    "            make_catplot(df, \"Source/Pipeline\", src, \"bar\", pdf_output)\n",
    "\n",
    "        else:\n",
    "            no_average = df.loc[df['SampleID'] != 'Average']\n",
    "            make_catplot(no_average, \"Pipeline\", src, \"box\", pdf_output)\n",
    "\n",
    "    pdf_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(combine_stats(\"genus\"), \"stats_summary_genus.pdf\")\n",
    "plot_stats(combine_stats(\"species\"), \"stats_summary_species.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
