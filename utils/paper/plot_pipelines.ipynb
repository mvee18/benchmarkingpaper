{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manuscript Utils\n",
    "This notebook contains useful functions for generating figures in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pylab import *\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../python_src/\")\n",
    "from figures_utils import generate_experimental_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables and Replacement Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_replace_dict = {\n",
    "    \"biobakery3\": \"bioBakery3\",\n",
    "    \"biobakery4\": \"bioBakery4\",\n",
    "    \"bio4\": \"bioBakery4\",\n",
    "    \"jams\": \"JAMS\",\n",
    "    \"wgsa2\": \"WGSA2\",\n",
    "    \"wgsa\": \"WGSA2\",\n",
    "    \"woltka\": \"Woltka\",\n",
    "    \"wol\": \"Woltka\",\n",
    "}\n",
    "\n",
    "left_join_replace_dict = {\"species_exp\": \"species\", \"genus_exp\": \"genus\", \"RA_obs\": \"RA\"}\n",
    "\n",
    "@dataclass\n",
    "class LegendAddition:\n",
    "    label: str\n",
    "    color: str\n",
    "    marker: str\n",
    "    alpha: float\n",
    "\n",
    "FP = LegendAddition(\"False Positive\", \"grey\", \"|\", 0.5)\n",
    "UNCLASS = LegendAddition(\"Unclassified\", \"#110a70\", \"x\", 0.5)\n",
    "ASSIGN_HIGHER = LegendAddition(\"Assigned Higher\", \"#f22e2e\", \"O\", 0.5)\n",
    "\n",
    "@dataclass\n",
    "class Columns:\n",
    "    false_positive: bool\n",
    "    unclass: bool\n",
    "    assigned_higher: bool\n",
    "\n",
    "# If this taxonomy number comes into use, then it will be in the far, far future\n",
    "ASSIGNED_HIGHER_ID = 999999999\n",
    "UNCLASS_ID = 12908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Plotting\n",
    "Stacked bar plots with tabulated relative abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_expected(root_dir: str, rank=\"Genus\") -> pd.DataFrame:\n",
    "    combined_expected = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            # print(\"files: \", files)\n",
    "            if f\"expected_{rank.lower()}_annotated\" in f and f.endswith(\".csv\"):\n",
    "                # print(root, f)\n",
    "                df = pd.read_csv(os.path.join(root, f), index_col=0, names=[rank, 'RA', \"TAX_ID\"], header=0)\n",
    "                df[\"Source\"] = root.split(\"/\")[-1]\n",
    "\n",
    "                # Files are of s#_expected.csv, so we can split on the underscore and take the first part.\n",
    "                df[\"SampleID\"] = f.split(\"_\")[0]\n",
    "\n",
    "                # Pipeline for easier grouping later.\n",
    "                df['Pipeline'] = \"Expected\"\n",
    "\n",
    "                combined_expected = pd.concat([combined_expected, df], axis=0)\n",
    "\n",
    "    return combined_expected\n",
    "\n",
    "def get_all_relabund_files(root_dir: str, rank=\"genus\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        root_dir: str \n",
    "            The root directory to search for relabund files.\n",
    "        rank: str\n",
    "            The taxonomic rank to search for. Default is \"genus\".\n",
    "    Returns:\n",
    "        relabund_files: pd.DataFrame\n",
    "\n",
    "    Traverses the BASE ROOT directory and searches for ALL {rank}_relabund_annotated files. These are concatenated. \\\\\n",
    "    Then, it then returns a dataframe with the sample ID and the path to the relabund file.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if f\"{rank.lower()}_relabund_annotated\" in f and f.endswith(\".csv\"):\n",
    "                # print(root, f)\n",
    "                p = os.path.join(root, f)\n",
    "                exp = generate_experimental_df(p, rank)\n",
    "                exp[\"Pipeline\"] = os.path.dirname(p).split('/')[-1]\n",
    "\n",
    "                # Add a column to the experimental dataframe with the pipeline name.\n",
    "                exp['Source'] = os.path.dirname(p).split('/')[-2]\n",
    "\n",
    "                # Add sampleID to the experimental dataframe.\n",
    "                exp['SampleID'] = os.path.basename(p).split('_')[0]\n",
    "                # display(exp.head(10))\n",
    "\n",
    "                # Add the experimental dataframe to the combined dataframe.\n",
    "                combined_df = pd.concat([combined_df, exp], axis=0)\n",
    "\n",
    "    # Ensure that the RA column is a float.\n",
    "    combined_df['RA'] = combined_df['RA'].astype(float)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# expected = get_all_expected(\"../../pipelines/\", rank=\"Genus\")\n",
    "# display(expected.head(50))\n",
    "# # Print the number of occurences in Source\n",
    "# expected[\"Source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pies(expected: pd.DataFrame):\n",
    "    for source, source_df in expected.groupby(\"Source\"):\n",
    "        for sample, sample_df in source_df.groupby(\"SampleID\"):\n",
    "            plot_df = sample_df.loc[sample_df[\"RA\"] > 0]\n",
    "\n",
    "            plot_df[[\"RA\"]].T.plot(kind=\"barh\", stacked=True, figsize=(20, 10))\n",
    "            plt.show()\n",
    "\n",
    "            plt.pie(plot_df[\"RA\"], labels=plot_df.index, autopct='%1.1f%%')\n",
    "            plt.show()\n",
    "\n",
    "            # sns.barplot(x='SampleID', y='RA', hue=\"Genus\", data=plot_df)\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of comparative stacked bar plots or heatmaps.\n",
    "\n",
    "We want to create a figure that summarizes the relative abundances of the expected with comparison to each pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_and_add_entry(ax: plt.Axes, c_objs: list[LegendAddition], contract: int = 15) -> Tuple[plt.Axes, str]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        ax: plt.Axes\n",
    "            The axes to add the legend entry to.\n",
    "        c_objs: list\n",
    "            A list of LegendAddition objects.\n",
    "        contract: int\n",
    "            The number of objects to contract the label to. Default is 15.\n",
    "    Returns:\n",
    "        ax: plt.Axes\n",
    "            The axes with the legend entry added.\n",
    "    Gets the legend from the axes and adds a new entry to it. \\\\\n",
    "    \"\"\"\n",
    "    # Get the legend from the axes.\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    if len (handles) >= contract:\n",
    "        # We want only the top 15 entries.\n",
    "        handles = handles[:contract]\n",
    "\n",
    "    # Add the new legend entry.\n",
    "    for obj in c_objs:\n",
    "        handles.append(mpatches.Patch(color=obj.color, label=obj.label, hatch=obj.marker, alpha=obj.alpha))\n",
    "\n",
    "    # Set the legend.\n",
    "    ax.legend(handles=handles, loc=\"upper left\", bbox_to_anchor=(1, 1), fontsize=16)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(df: pd.DataFrame, rank: str, name: str, value: any, taxid: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a row with the given value and name to the dataframe.\n",
    "    \"\"\"\n",
    "    df.reset_index(inplace=True)\n",
    "    df.index.names = [rank]\n",
    "\n",
    "    new_row = pd.DataFrame({rank: name, \"RA\": value, \"TAX_ID\": taxid}, index=[0])\n",
    "    df = pd.concat([df, new_row], axis=0)\n",
    "\n",
    "    df = df.set_index(rank)\n",
    "\n",
    "    return df\n",
    "\n",
    "def fill_df(df: pd.DataFrame, src: str, rank: str, row_name: str = \"Unclassified\") -> Tuple[pd.DataFrame, bool]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        df: pd.DataFrame\n",
    "            The dataframe to fill.\n",
    "        src: str\n",
    "            The source of the dataframe.\n",
    "        rank: str\n",
    "            The taxonomic rank of the dataframe.\n",
    "        row_name: str\n",
    "            The name of the row which will fill. Default is \"Unclassified\".\n",
    "    Returns:\n",
    "        df: pd.DataFrame\n",
    "            The dataframe with the row filled.\n",
    "        filled: bool\n",
    "            Whether or not the row was filled.\n",
    "    \n",
    "    Fills the input dataframe in the RA column up to 100% with a row of the input row_name. \\\\\n",
    "    \"\"\"\n",
    "    # We need to get the sum of the RA column for the dataframe.\n",
    "    # If it it less than 1, we need to fill the difference with a row called \"Unclassified\".\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Get the sum of the RA column.\n",
    "    sum_ra = df[\"RA\"].sum()\n",
    "    diff = 1 - sum_ra\n",
    "    # print(diff)\n",
    "\n",
    "    # If the difference is less than zero, we do not need to add anything.\n",
    "    if diff <= 0:\n",
    "        df.set_index(rank, inplace=True)\n",
    "        return df, False\n",
    "\n",
    "    # Rename index to rank.\n",
    "    df.index.names = [rank]\n",
    "\n",
    "    # If the difference is greater than 0, we need to add a row.\n",
    "    # new_row = pd.DataFrame({rank: \"Unclassified\", \"RA\": diff, \"TAX_ID\": \"Unclassified\", \"Source\": src, \"SampleID\": sampleID, \"Pipeline\": \"wgsa2\"}, index=[0])\n",
    "    new_row = pd.DataFrame({rank: row_name, \"RA\": diff}, index=[0])\n",
    "    df = pd.concat([df, new_row], axis=0)\n",
    "\n",
    "    # print(df[\"RA\"].sum())\n",
    "    # display(df)\n",
    "\n",
    "    df.set_index(rank, inplace=True)\n",
    "\n",
    "    return df, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inverse_range(n: int) -> List[int]:\n",
    "    # We want to take n (ex. 1) and make a range of [-2].\n",
    "    # For n = 2, we want [-3, -2].\n",
    "    # For n = 3, we want [-4, -3, -2].\n",
    "    lst = []\n",
    "    for i in range(n):\n",
    "        lst.append(-i - 2)\n",
    "\n",
    "    return reversed(lst)\n",
    "\n",
    "def fix_bar_colors(ax: plt.Axes, labels_list: List[Tuple[str, str, str]]):\n",
    "    \"\"\"\n",
    "    Changes the last bar in the ax to be black. We also need to change the second to last color to a hatched red? \\\\\n",
    "    This is done because the legend entry \"False Positive\" is black and the last bar needs to match. Same for the \"Unclassifed\".\n",
    "\n",
    "    Parameters:\n",
    "        ax: plt.Axes\n",
    "            The axes to change the color of.\n",
    "        labels_list: List[Tuple[str, str, str]]\n",
    "            A list of tuples containing the labels of the bars. The first index is the label name, the second is whether is it present or not, and the third is the color class.\n",
    "            The order is \n",
    "    \"\"\"\n",
    "    children = ax.get_children()\n",
    "\n",
    "    filtered = filter(lambda x: isinstance(x, matplotlib.patches.Rectangle), children)\n",
    "    filtered_list = list(filtered)\n",
    "\n",
    "    def fix_color(rect, props: LegendAddition):\n",
    "        rect.set_facecolor(props.color)\n",
    "        rect.set_hatch(props.marker)\n",
    "        rect.set_alpha(props.alpha)\n",
    "\n",
    "    # false_p = filtered_list[-2]\n",
    "    # unclass = filtered_list[-3]\n",
    "    labels_list = [x for x in labels_list if x[1]]\n",
    "    n = len(labels_list)\n",
    "\n",
    "    idxs = make_inverse_range(n)\n",
    "\n",
    "    for c, i in enumerate(make_inverse_range(n)):\n",
    "        fix_color(filtered_list[i], labels_list[c][2])\n",
    "\n",
    "    # filtered2 = filter(lambda x: isinstance(x, matplotlib.patches.Rectangle), children)\n",
    "    # list(filtered2)[-3].set_facecolor(\"#110a70\").set_alpha(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_columns(df: pd.DataFrame, cols_list: List[Tuple[str, bool]]):\n",
    "    \"\"\"\n",
    "    Reorganizes the columns into the proper order so that colors may be assigned to the correct bars.\n",
    "    Parameters:\n",
    "        df: The dataframe to reorganize.\n",
    "        cols_list: A list of tuples. The first element is the column name and the second is a boolean indicating if the column is present.\n",
    "    \"\"\"\n",
    "    cols = list(df.columns.values)    \n",
    "\n",
    "    reorg_list = [x[0] for x in cols_list if x[1]]\n",
    "\n",
    "    for label in reorg_list:\n",
    "        cols.pop(cols.index(label))\n",
    "    \n",
    "    return df[cols + reorg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_plot_decorations(ax, n_rows):\n",
    "    \"\"\"\n",
    "    This function adds a box around the pipelines and adds a textbox with the word \"Observed\" at 90 degrees.\n",
    "    \"\"\"\n",
    "    # We now need to add an external rectangle to the first plot, the one enclosing the rest.\n",
    "    autoAxis = ax[0].axis()\n",
    "    rec = Rectangle((autoAxis[0]-0.15,autoAxis[2]),(autoAxis[1]-autoAxis[0]+0.151),(autoAxis[3]-autoAxis[2]),fill=False,lw=3)\n",
    "    rec = ax[0].add_patch(rec)\n",
    "    rec.set_clip_on(False)\n",
    "\n",
    "    # Now, from the second axis down.\n",
    "    autoAxis = ax[1].axis()\n",
    "    box_height = autoAxis[3] - autoAxis[2] + 0.205\n",
    "    height_mult = n_rows - 2\n",
    "    # Distance between plots.\n",
    "    rec = Rectangle((autoAxis[0]-0.15,autoAxis[2]-(box_height*height_mult)),(autoAxis[1]-autoAxis[0]+0.151),(autoAxis[3]-autoAxis[2]+(box_height*height_mult)),fill=False,lw=3)\n",
    "    rec = ax[1].add_patch(rec)\n",
    "    rec.set_clip_on(False)\n",
    "\n",
    "    pts = rec.get_bbox()\n",
    "\n",
    "    ax[1].text(pts.x0, pts.y0 / 2, \"Observed\", fontsize=24, ha=\"right\", va=\"bottom\", rotation=90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expected(ax: plt.Axes, df: pd.DataFrame, max_legend_entries: int = 15):\n",
    "    \"\"\"\n",
    "    ## Parameters:\n",
    "        ax: The axis to plot on.\n",
    "        df: The dataframe to plot (should be the expected dataframe).\n",
    "    \n",
    "    Plots the expected values for the given ax.\n",
    "    \"\"\"\n",
    "    group_T = df[[\"RA\"]].T\n",
    "    group_T.index = [\"Expected\"]\n",
    "    group_T.plot.barh(stacked=True, ax=ax[0], alpha=0.5, legend=True, fontsize=20)\n",
    "\n",
    "    ax[0].set_xlim(0, 1.01)\n",
    "\n",
    "    ax[0] = get_legend_and_add_entry(ax[0], [UNCLASS, FP, ASSIGN_HIGHER], max_legend_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rows_to_expected(df: pd.DataFrame, rank: str) -> pd.DataFrame:\n",
    "    df = add_row(df, rank, \"Assigned Higher\", 0.0, ASSIGNED_HIGHER_ID)\n",
    "    df = add_row(df, rank, \"Unclassified\", 0.0, UNCLASS_ID)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_to_one(smpl_df: pd.DataFrame, expected: pd.DataFrame, src: str, smpl: str, rank: str): \n",
    "    n_rows = len(smpl_df[\"Pipeline\"].unique()) + 1\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=1, figsize=(20, 10), sharex=True)\n",
    "    fig.suptitle(f\"Relative Abundances between Observed and Expected for {src} {smpl} at {rank.capitalize()} Level\", fontsize=16, y=0.92)\n",
    "    \n",
    "    ax_c = 1\n",
    "\n",
    "    grouped_expected = expected.loc[(expected[\"Source\"] == src) & (expected[\"SampleID\"] == smpl) & (expected[\"RA\"] > 0)]\n",
    "    sorted_expected = grouped_expected.copy().sort_index()\n",
    "    # display(sorted_expected)\n",
    "    plot_expected(ax, sorted_expected, 30)    \n",
    "\n",
    "    # display(sorted_expected)\n",
    "    sorted_expected = add_rows_to_expected(sorted_expected, rank)\n",
    "    display(sorted_expected)\n",
    "\n",
    "    # Get the TAX_ID values from the expected as a set.\n",
    "    # We add 12908 becasue that is the TAX_ID for \"Unclassified\". We also add the assigned_higher ID (9 9s).\n",
    "    # expected_tax_ids_set = set(sorted_expected[\"TAX_ID\"].values)\n",
    "    # expected_tax_ids_set.add(12908)\n",
    "    # expected_tax_ids_set.add(ASSIGNED_HIGHER_ID)\n",
    "\n",
    "    for pl, pl_df in smpl_df.groupby(\"Pipeline\"):\n",
    "        # Get observed total.\n",
    "        observed_total = pl_df[\"RA\"].sum()\n",
    "\n",
    "        # The difference between 1 and the observed total is assigned higher.\n",
    "        assigned_higher_ra = 0\n",
    "        assigned_higher_bool = False\n",
    "\n",
    "        if pl != \"woltka\":\n",
    "            assigned_higher_ra = 1 - observed_total\n",
    "            assigned_higher_bool = assigned_higher_ra > 1e-6\n",
    "\n",
    "        # Add the assigned higher to the dataframe if it is greater than 1 ppm.\n",
    "        if assigned_higher_bool:\n",
    "            pl_df = add_row(pl_df, rank, \"Assigned Higher\", assigned_higher_ra, ASSIGNED_HIGHER_ID)\n",
    "\n",
    "        # Select the rows from the observed that are in the expected set.\n",
    "        # left_joined = pd.merge(grouped_expected, pl_df, how=\"left\", on=[\"TAX_ID\"], suffixes=(\"_obs\", \"_exp\"))\n",
    "        left_joined = sorted_expected.reset_index().merge(pl_df.reset_index(), how=\"left\", on=[\"TAX_ID\"], suffixes=(\"_exp\", \"_obs\"))\n",
    "        # pl_df = pl_df.loc[pl_df[\"TAX_ID\"].isin(expected_tax_ids_set)]\n",
    "\n",
    "        left_joined = left_joined.loc[(left_joined[\"RA_exp\"].notna()) | (left_joined[f\"{rank}_exp\"] == \"Unclassified\") | (left_joined[f\"{rank}_exp\"] == \"Assigned Higher\")]\n",
    "        left_joined = left_joined[[f\"{rank}_exp\", \"RA_obs\", \"TAX_ID\"]].fillna(0)\n",
    "        left_joined.rename(left_join_replace_dict, axis=1, inplace=True)\n",
    "        left_joined.set_index(rank, inplace=True)\n",
    "\n",
    "        # display(pl_df)\n",
    "\n",
    "        # Find the index value of the row with TAX_ID 12908.\n",
    "        unclassified_present = 12908 in left_joined[\"TAX_ID\"].values\n",
    "\n",
    "        unclassified_label = None\n",
    "        if unclassified_present:\n",
    "            unclassified_label = left_joined.loc[left_joined[\"TAX_ID\"] == 12908].index[0]\n",
    "\n",
    "        left_joined, fp_filled = fill_df(left_joined, src, rank, \"False Positive\")\n",
    "        # display(left_joined.head(10))\n",
    "        T = left_joined[[\"RA\"]].T\n",
    "\n",
    "        # Sort the columns in alphabetical order.\n",
    "        # T = T.reindex(sorted(T.columns), axis=1)\n",
    "\n",
    "        # We need to remove the column \"Unclassified\" from the expected dataframe and remove the 'False Positive' column from the observed dataframe.\n",
    "        # Then append these to the end of the df in the order \"Unclass\" then \"False Positive\", then Assign Higher.\n",
    "        reorg_list = [(unclassified_label, unclassified_present, UNCLASS), (\"False Positive\", fp_filled, FP), (\"Assigned Higher\", assigned_higher_bool, ASSIGN_HIGHER)]\n",
    "\n",
    "        T = reorganize_columns(T, reorg_list)\n",
    "        \n",
    "        # Change the index to the pipeline name.\n",
    "        T.index = [name_replace_dict[pl]]\n",
    "\n",
    "        display(T)\n",
    "\n",
    "        ax[ax_c].set_xlim(0, 1.01)\n",
    "        T.plot.barh(alpha=0.5, ax=ax[ax_c], legend=False, stacked=True, fontsize=20)\n",
    "        # ax[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        fix_bar_colors(ax[ax_c], reorg_list)\n",
    "\n",
    "        ax[ax_c].set_xlabel(\"Relative Abundance\", fontsize=24, labelpad=20)\n",
    "\n",
    "        ax_c += 1\n",
    "\n",
    "    add_plot_decorations(ax, n_rows) \n",
    "\n",
    "    pdf_output.savefig(fig, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want the charts to represent the left join of the expected and observed dataframes.\n",
    "# This is to reduce the number of taxa.\n",
    "pdf_output = PdfPages(\"pipeline_plotting.pdf\")\n",
    "\n",
    "def stacked_left_join(rank: str):\n",
    "    expected = get_all_expected(\"../../pipelines/\", rank=rank)\n",
    "    observed = get_all_relabund_files(\"../../pipelines/\", rank=rank)\n",
    "\n",
    "    for src, src_df in observed.groupby(\"Source\"):\n",
    "        print(src)\n",
    "        if src == \"gut\" or src == \"tongue\":\n",
    "            continue\n",
    "\n",
    "        if src == \"bmock12\" or src == \"camisimGI\" or src == \"nist\":\n",
    "            groups = src_df.groupby(\"SampleID\")\n",
    "            for smpl, smpl_df in groups:\n",
    "                print(\"Sample: \", smpl)\n",
    "                plot_one_to_one(smpl_df, expected, src, smpl, rank)\n",
    "                \n",
    "        else:\n",
    "            groups = src_df.groupby(\"Pipeline\")\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=len(groups)+1, ncols=1, figsize=(20, 10), sharex=True)\n",
    "            fig.suptitle(f\"Average Relative Abundances between Observed and Expected for {src} at {rank} Level\", fontsize=20, y=0.95)\n",
    "            ax_c = 1\n",
    "\n",
    "            grouped_expected = expected.loc[(expected[\"Source\"] == src) & (expected[\"RA\"] > 0)]\n",
    "            grouped_expected = grouped_expected.copy().sort_index()\n",
    "            plot_expected(ax, grouped_expected, 30)\n",
    "\n",
    "            sorted_expected = add_row(grouped_expected, rank, \"Unclassified\", 0.0, UNCLASS_ID)\n",
    "\n",
    "            for pl, pl_df in groups:\n",
    "                left_joined = sorted_expected.reset_index().merge(pl_df.reset_index(), how=\"left\", on=[\"TAX_ID\"], suffixes=(\"_exp\", \"_obs\"))\n",
    "\n",
    "                left_joined = left_joined.loc[(left_joined[\"RA_exp\"].notna()) | (left_joined[f\"{rank}_exp\"] == \"Unclassified\")]\n",
    "                left_joined = left_joined[[f\"{rank}_exp\", \"RA_obs\", \"TAX_ID\"]].fillna(0)\n",
    "                left_joined.rename(left_join_replace_dict, axis=1, inplace=True)\n",
    "                left_joined.set_index(rank, inplace=True)\n",
    "\n",
    "                avg_df = left_joined[['RA', 'TAX_ID']].groupby(rank).mean()\n",
    "\n",
    "                # Get observed total.\n",
    "                observed_total = avg_df[\"RA\"].sum()\n",
    "\n",
    "                # The difference between 1 and the observed total is assigned higher.\n",
    "                assigned_higher_ra = 0\n",
    "                assigned_higher_bool = False\n",
    "\n",
    "                if pl != \"woltka\":\n",
    "                    assigned_higher_ra = 1 - observed_total\n",
    "                    assigned_higher_bool = assigned_higher_ra > 1e-6\n",
    "\n",
    "                # Add the assigned higher to the dataframe if it is greater than 1 ppm.\n",
    "                if assigned_higher_bool:\n",
    "                    avg_df = add_row(avg_df, rank, \"Assigned Higher\", assigned_higher_ra, ASSIGNED_HIGHER_ID)\n",
    "\n",
    "                unclassified_present = 12908 in avg_df[\"TAX_ID\"].values\n",
    "\n",
    "                unclassified_label = None\n",
    "                if unclassified_present:\n",
    "                    unclassified_label = avg_df.loc[avg_df[\"TAX_ID\"] == 12908].index[0]\n",
    "                \n",
    "                # Drop the TAX_ID column.\n",
    "                avg_df = avg_df.drop(columns=[\"TAX_ID\"])\n",
    "\n",
    "                avg_df, fp_filled = fill_df(avg_df, src, rank, \"False Positive\")\n",
    "                # display(pl_df.head(10))\n",
    "                T = avg_df[[\"RA\"]].T\n",
    "\n",
    "                display(T)\n",
    "\n",
    "                T = T.reindex(sorted(T.columns), axis=1)\n",
    "\n",
    "                reorg_list = [(unclassified_label, unclassified_present, UNCLASS), (\"False Positive\", fp_filled, FP), (\"Assigned Higher\", assigned_higher_bool, ASSIGN_HIGHER)]\n",
    "\n",
    "                T = reorganize_columns(T, reorg_list)\n",
    "                \n",
    "                # Change the index to the pipeline name.\n",
    "                T.index = [name_replace_dict[pl]]\n",
    "\n",
    "                ax[ax_c].set_xlim(0, 1.01)\n",
    "\n",
    "                T.plot.barh(alpha=0.5, legend=False, stacked=True, ax=ax[ax_c], fontsize=20)\n",
    "\n",
    "                fix_bar_colors(ax[ax_c], reorg_list)\n",
    "                                \n",
    "                ax[ax_c].set_xlabel(\"Average Relative Abundance\", fontsize=24, labelpad=20)\n",
    "\n",
    "                ax_c += 1\n",
    "            \n",
    "            add_plot_decorations(ax=ax, n_rows=len(groups)+1)\n",
    "            pdf_output.savefig(fig, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "# stacked_left_join(\"genus\")\n",
    "stacked_left_join(\"species\")\n",
    "\n",
    "pdf_output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
