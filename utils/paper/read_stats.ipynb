{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Stats\n",
    "This notebook will take the directory of trimmed read stats, concatenate for an overall dataframe, then generate the wanted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camisim_trim.out', 'tourlousse_trim.out', 'amos_hilo_trim.out', 'bmock12_trim.out', 'nist_trim.out', 'amos_mixed_trim.out', 'hmp_gut_trim.out']\n"
     ]
    }
   ],
   "source": [
    "trim_reads_path = \"/Volumes/TBHD_share/valencia/pipelines/read_stats/trimmed\"\n",
    "files = os.listdir(trim_reads_path)\n",
    "files = [f for f in files if f.endswith(\".out\")]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Community', 'num_seqs', 'sum_len', 'min_len', 'avg_len', 'max_len']\n",
      "['Community', 'num_seqs', 'sum_len', 'min_len', 'avg_len', 'max_len']\n",
      "['Community', 'num_seqs', 'sum_len', 'min_len', 'avg_len', 'max_len']\n",
      "['Community', 'num_seqs', 'sum_len', 'min_len', 'avg_len', 'max_len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_seqs</th>\n",
       "      <th>sum_len</th>\n",
       "      <th>min_len</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>max_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Community</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub_bmock12</th>\n",
       "      <td>100500000.00 ± 0.00</td>\n",
       "      <td>15175500000.00 ± 0.00</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1_camisim</th>\n",
       "      <td>16666158.00 ± 0.00</td>\n",
       "      <td>2473504212.50 ± 12668039.31</td>\n",
       "      <td>31.00 ± 0.00</td>\n",
       "      <td>148.45 ± 0.78</td>\n",
       "      <td>150.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2_camisim</th>\n",
       "      <td>16666291.00 ± 0.00</td>\n",
       "      <td>2473723888.00 ± 12664634.59</td>\n",
       "      <td>31.00 ± 0.00</td>\n",
       "      <td>148.45 ± 0.78</td>\n",
       "      <td>150.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG_nist</th>\n",
       "      <td>3353278.00 ± 0.00</td>\n",
       "      <td>282025983.00 ± 3833426.68</td>\n",
       "      <td>15.00 ± 0.00</td>\n",
       "      <td>84.10 ± 1.13</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix-A_nist</th>\n",
       "      <td>3473553.00 ± 0.00</td>\n",
       "      <td>365925482.50 ± 2529868.96</td>\n",
       "      <td>19.00 ± 5.66</td>\n",
       "      <td>105.35 ± 0.78</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix-B_nist</th>\n",
       "      <td>3583192.00 ± 0.00</td>\n",
       "      <td>376371686.50 ± 2769876.56</td>\n",
       "      <td>18.50 ± 4.95</td>\n",
       "      <td>105.05 ± 0.78</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix-C_nist</th>\n",
       "      <td>2974354.00 ± 0.00</td>\n",
       "      <td>325816856.00 ± 2268975.55</td>\n",
       "      <td>16.50 ± 2.12</td>\n",
       "      <td>109.55 ± 0.78</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix-D_nist</th>\n",
       "      <td>3278203.00 ± 0.00</td>\n",
       "      <td>373347674.50 ± 2103394.48</td>\n",
       "      <td>20.00 ± 7.07</td>\n",
       "      <td>113.85 ± 0.64</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tourlousse</th>\n",
       "      <td>5897627.83 ± 378678.85</td>\n",
       "      <td>855639825.08 ± 51884672.55</td>\n",
       "      <td>15.00 ± 0.00</td>\n",
       "      <td>145.12 ± 1.31</td>\n",
       "      <td>151.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amos_hilo</th>\n",
       "      <td>1899005.80 ± 172132.60</td>\n",
       "      <td>380831440.00 ± 34742124.05</td>\n",
       "      <td>100.00 ± 0.00</td>\n",
       "      <td>200.54 ± 1.93</td>\n",
       "      <td>205.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amos_mixed</th>\n",
       "      <td>2012091.00 ± 184747.85</td>\n",
       "      <td>403848279.20 ± 37416661.58</td>\n",
       "      <td>100.00 ± 0.00</td>\n",
       "      <td>200.71 ± 1.55</td>\n",
       "      <td>205.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmp_gut</th>\n",
       "      <td>2901295.10 ± 356896.97</td>\n",
       "      <td>269739388.40 ± 34622935.73</td>\n",
       "      <td>15.00 ± 0.00</td>\n",
       "      <td>92.91 ± 1.01</td>\n",
       "      <td>101.00 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           num_seqs                      sum_len  \\\n",
       "Community                                                          \n",
       "sub_bmock12     100500000.00 ± 0.00        15175500000.00 ± 0.00   \n",
       "S1_camisim       16666158.00 ± 0.00  2473504212.50 ± 12668039.31   \n",
       "S2_camisim       16666291.00 ± 0.00  2473723888.00 ± 12664634.59   \n",
       "EG_nist           3353278.00 ± 0.00    282025983.00 ± 3833426.68   \n",
       "Mix-A_nist        3473553.00 ± 0.00    365925482.50 ± 2529868.96   \n",
       "Mix-B_nist        3583192.00 ± 0.00    376371686.50 ± 2769876.56   \n",
       "Mix-C_nist        2974354.00 ± 0.00    325816856.00 ± 2268975.55   \n",
       "Mix-D_nist        3278203.00 ± 0.00    373347674.50 ± 2103394.48   \n",
       "tourlousse   5897627.83 ± 378678.85   855639825.08 ± 51884672.55   \n",
       "amos_hilo    1899005.80 ± 172132.60   380831440.00 ± 34742124.05   \n",
       "amos_mixed   2012091.00 ± 184747.85   403848279.20 ± 37416661.58   \n",
       "hmp_gut      2901295.10 ± 356896.97   269739388.40 ± 34622935.73   \n",
       "\n",
       "                   min_len        avg_len        max_len  \n",
       "Community                                                 \n",
       "sub_bmock12  151.00 ± 0.00  151.00 ± 0.00  151.00 ± 0.00  \n",
       "S1_camisim    31.00 ± 0.00  148.45 ± 0.78  150.00 ± 0.00  \n",
       "S2_camisim    31.00 ± 0.00  148.45 ± 0.78  150.00 ± 0.00  \n",
       "EG_nist       15.00 ± 0.00   84.10 ± 1.13  151.00 ± 0.00  \n",
       "Mix-A_nist    19.00 ± 5.66  105.35 ± 0.78  151.00 ± 0.00  \n",
       "Mix-B_nist    18.50 ± 4.95  105.05 ± 0.78  151.00 ± 0.00  \n",
       "Mix-C_nist    16.50 ± 2.12  109.55 ± 0.78  151.00 ± 0.00  \n",
       "Mix-D_nist    20.00 ± 7.07  113.85 ± 0.64  151.00 ± 0.00  \n",
       "tourlousse    15.00 ± 0.00  145.12 ± 1.31  151.00 ± 0.00  \n",
       "amos_hilo    100.00 ± 0.00  200.54 ± 1.93  205.00 ± 0.00  \n",
       "amos_mixed   100.00 ± 0.00  200.71 ± 1.55  205.00 ± 0.00  \n",
       "hmp_gut       15.00 ± 0.00   92.91 ± 1.01  101.00 ± 0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_df(file: str, name: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(os.path.join(trim_reads_path, file), delim_whitespace=True, header=None, names=col_names)\n",
    "    df[\"Community\"] = name\n",
    "\n",
    "    # We want to split the file column on the final / and take the last element.\n",
    "    df[\"file\"] = df[\"file\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "    # Sort the dataframe by the file column.\n",
    "    df = df.sort_values(\"file\")\n",
    "\n",
    "    # Convert num_seqs and sum_len to integers.\n",
    "    def convert_column(col: str) -> None:\n",
    "        df[col] = df[col].apply(lambda x: int(x.replace(\",\", \"\")))\n",
    "        df[col].astype(int)\n",
    "\n",
    "    convert_column(\"num_seqs\")\n",
    "    convert_column(\"sum_len\")\n",
    "\n",
    "    df.set_index(\"file\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "col_names = [\"file\", \"format\", \"type\", \"num_seqs\", \"sum_len\", \"min_len\", \"avg_len\", \"max_len\"]\n",
    "\n",
    "def parse_files() -> pd.DataFrame:\n",
    "    replicates_df = pd.DataFrame()\n",
    "    one_to_one_df = pd.DataFrame()\n",
    "\n",
    "    for f in files:\n",
    "        if \"bmock12\" in f or \"camisim\" in f or \"nist\" in f:\n",
    "            name = f.split(\"_\")[0]\n",
    "            df = make_df(f, name)\n",
    "\n",
    "            one_to_one_df = pd.concat([one_to_one_df, df])\n",
    "\n",
    "        else:\n",
    "            # These are the replicate studies.\n",
    "            split = f.split(\"_\")\n",
    "            split.pop()\n",
    "            name = \"_\".join(split)\n",
    "\n",
    "            df = make_df(f, name)\n",
    "\n",
    "            # We want to add a row for the average of the replicates.\n",
    "            average = df.mean(numeric_only=True)\n",
    "            stddev = df.std(numeric_only=True)\n",
    "\n",
    "            col_labels = [\"Community\"] + average.index.to_list()\n",
    "            print(col_labels)\n",
    "\n",
    "            # How many decimals do we want to show?\n",
    "            new_row = [f\"{i:.2f} ± {stddev[c]:.2f}\" for c, i in enumerate(average)]\n",
    "            new_row.insert(0, name)\n",
    "\n",
    "            replicates_df = pd.concat([replicates_df, pd.DataFrame([new_row], columns=col_labels)])\n",
    "\n",
    "    return one_to_one_df, replicates_df\n",
    "\n",
    "one_to_one, replicates_df = parse_files()\n",
    "one_to_one_stats = pd.DataFrame()\n",
    "\n",
    "one_to_one = one_to_one.loc[(one_to_one.index != \"Neg_S6_L001_R1.fastq\") & (one_to_one.index != \"Neg_S6_L001_R2.fastq\")]\n",
    "for comm, pl_df in one_to_one.groupby(\"Community\"):\n",
    "    pl_df = pl_df[[\"num_seqs\", \"sum_len\", \"min_len\", \"avg_len\", \"max_len\"]]\n",
    "    pl_df.reset_index(inplace=True)\n",
    "    # We want to average every two rows\n",
    "    pl_df_avg_grp = pl_df.groupby(pl_df.index // 2)\n",
    "    for name, group in pl_df_avg_grp:\n",
    "        new_name = group.iloc[0][\"file\"].split(\"_\")[0] + f\"_{comm}\"\n",
    "        grp_avg = group.mean(numeric_only=True)\n",
    "        grp_std = group.std(numeric_only=True)\n",
    "\n",
    "        col_labels = [\"Community\"] + grp_avg.index.to_list()\n",
    "\n",
    "        new_row = [f\"{i:.2f} ± {grp_std[c]:.2f}\" for c, i in enumerate(grp_avg)]\n",
    "        new_row.insert(0, new_name)\n",
    "\n",
    "        one_to_one_stats = pd.concat([one_to_one_stats, pd.DataFrame([new_row], columns=col_labels)])\n",
    "\n",
    "final_df = pd.concat([one_to_one_stats, replicates_df])\n",
    "final_df.set_index(\"Community\", inplace=True)\n",
    "display(final_df)\n",
    "\n",
    "final_df.to_csv(\"read_stats.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
