{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sys  # noqa\n",
    "sys.path.append('../..')  # noqa\n",
    "\n",
    "from utils.data_paths import make_data_list\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OutputLogs:\n",
    "    \"\"\" Holds the paths to the output logs for each pipeline. \"\"\"\n",
    "    bio3: str = \"\"\n",
    "    bio4: str = \"\"\n",
    "    jams: list[str] = field(default_factory=list)\n",
    "    wgsa2: str = \"\"\n",
    "    woltka: list[str] = field(default_factory=list)\n",
    "    sunbeam: str = \"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TimeData:\n",
    "    \"\"\" Holds the average or total time for each pipeline.\"\"\"\n",
    "    bio3: timedelta = timedelta()\n",
    "    bio4: timedelta = timedelta()\n",
    "    jams: timedelta = timedelta()\n",
    "    wgsa2: timedelta = timedelta()\n",
    "    woltka: timedelta = timedelta()\n",
    "    sunbeam: timedelta = timedelta()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ThreadData:\n",
    "    \"\"\" Holds the number of CPUS used in each run. \"\"\"\n",
    "    bio3: int = 0\n",
    "    bio4: int = 0\n",
    "    jams: int = 0\n",
    "    wgsa2: int = 0\n",
    "    woltka: int = 0\n",
    "    sunbeam: int = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_files(path: str):\n",
    "    \"\"\" Look for anadama.log, JAMS logs, WGSA logs, Wolka, and Sunbeam logs.\"\"\"\n",
    "    data_obj = OutputLogs()\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # print(files)\n",
    "        for f in files:\n",
    "            if f == \"anadama.log\":\n",
    "                if \"bio4\" in root:\n",
    "                    data_obj.bio4 = os.path.join(root, f)\n",
    "                elif \"bio3\" in root:\n",
    "                    data_obj.bio3 = os.path.join(root, f)\n",
    "            elif f.endswith(\"JAMS.log\"):\n",
    "                # Don't add the beta log or the negative control log.\n",
    "                if \"beta\" in root or \"Neg\" in f:\n",
    "                    continue\n",
    "                else:\n",
    "                    data_obj.jams.append(os.path.join(root, f))\n",
    "            elif f == \"logfile.txt\":\n",
    "                data_obj.wgsa2 = os.path.join(root, f)\n",
    "\n",
    "            elif f == \"classify_time.log\" or f == \"bowtie_time.log\":\n",
    "                data_obj.woltka.append(os.path.join(root, f))\n",
    "\n",
    "            # elif re.match(\"\\d+_benchmarks.tsv\", f):\n",
    "            #     data_obj.sunbeam = os.path.join(root, f)\n",
    "\n",
    "            elif f == \"sunbeam.log\":\n",
    "                data_obj.sunbeam = os.path.join(root, f)\n",
    "\n",
    "    return data_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "anadama_format = \"%Y-%m-%d %H:%M:%S,%f\"\n",
    "wanted_time_fmt = \"%H:%M:%S\"\n",
    "\n",
    "\n",
    "def parse_bio_time(log_path: str):\n",
    "    \"\"\"Parse the anadama.log file to get the start and end times.\"\"\"\n",
    "    # First line is the start time, last line is the end time.\n",
    "\n",
    "    with open(log_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        start = datetime.strptime(\n",
    "            lines[0].strip().split('\\t')[0], anadama_format)\n",
    "        end = datetime.strptime(\n",
    "            lines[-1].strip().split('\\t')[0], anadama_format)\n",
    "\n",
    "        # Find the line that has \"threads\" in it.\n",
    "        threads = 0\n",
    "        for line in lines:\n",
    "            if \"threads\" in line:\n",
    "                # Get the number of threads used.\n",
    "                threads = int(line.split(' ')[-1])\n",
    "                break\n",
    "\n",
    "        elapsed = end - start\n",
    "\n",
    "        return elapsed, threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "jams_format_time = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "\n",
    "def average_time(times: list):\n",
    "    \"\"\" Get the average time for each pipeline. \"\"\"\n",
    "    average = sum(times, timedelta()) / len(times)\n",
    "    return average\n",
    "\n",
    "\n",
    "def parse_jams_time(logs: list):\n",
    "    \"\"\" Parse all of the JAMS logs. \"\"\"\n",
    "\n",
    "    cpu_regex = \"Saving project workspace image using fastSave package with \\d+ CPUs\"\n",
    "\n",
    "    times = []\n",
    "\n",
    "    # They all ran with the same number of threads, so we can overwrite this in the for loop.\n",
    "    threads = 0\n",
    "    for l in logs:\n",
    "        # open the file\n",
    "        with open(l, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # First line is start time.\n",
    "            start = \" \".join(lines[0].strip().split()[1:3]).strip(\"[]\")\n",
    "            start_time = datetime.strptime(start, jams_format_time)\n",
    "            # Last line is end time.\n",
    "            end = \" \".join(lines[-1].strip().split()[1:3]).strip(\"[]\")\n",
    "            end_time = datetime.strptime(end, jams_format_time)\n",
    "\n",
    "            for line in lines:\n",
    "                if \"Saving project workspace image using fastSave package with\" in line:\n",
    "                    threads = int(line.split()[-2])\n",
    "                    break\n",
    "\n",
    "            elapsed = end_time - start_time\n",
    "\n",
    "            times.append(elapsed)\n",
    "\n",
    "    return average_time(times), threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wgsa2(file_path: str):\n",
    "    \"\"\" Parse the WGSA output log for the time.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        start = \" \".join(lines[0].strip().split()[0:2]).strip(\"[]\")\n",
    "        start_time = datetime.strptime(start, anadama_format)\n",
    "        # Last line is end time.\n",
    "        end = \" \".join(lines[-1].strip().split()[0:2]).strip(\"[]\")\n",
    "        end_time = datetime.strptime(end, anadama_format)\n",
    "\n",
    "        threads = 0\n",
    "        for line in lines:\n",
    "            if 'Provided cores:' in line:\n",
    "                threads = int(line.split()[-1])\n",
    "                break\n",
    "\n",
    "        elapsed = end_time - start_time\n",
    "        return elapsed, threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_woltka_time(logs: list):\n",
    "    times = []\n",
    "    for log in logs:\n",
    "        # Second line gives column widths.\n",
    "        with open(log, 'r') as f:\n",
    "            dash_line = f.readlines()[1].strip().split()\n",
    "            widths = [len(x)+1 for x in dash_line]\n",
    "\n",
    "            df = pd.read_fwf(log, widths=widths, skiprows=[1], header=0)\n",
    "            df = df.loc[df[\"JobName\"] == \"swarm\"]\n",
    "\n",
    "            # Split along the colon. This is of the format DD:HH:MM.\n",
    "            df[\"Elapsed\"] = df[\"Elapsed\"].str.split(\":\").apply(\n",
    "                lambda x: timedelta(days=int(x[0]), hours=int(x[1]), minutes=int(x[2])))\n",
    "\n",
    "            avg_td = df[\"Elapsed\"].mean()\n",
    "\n",
    "            times.append(avg_td)\n",
    "\n",
    "    # Sum of the bowtie and classify times.\n",
    "    total_time = sum(times, timedelta())\n",
    "    return total_time.to_pytimedelta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sunbeam(file_path: str) -> Tuple[timedelta, int]:\n",
    "    # We will read the sunbeam.log file. We want lines that match the following expression: [Tue Apr 11 13:59:32 2023].\n",
    "\n",
    "    # We will use a regex to match the date and time.\n",
    "    regex = \"\\[\\w{3} \\w{3} \\d{2} \\d{2}:\\d{2}:\\d{2} \\d{4}\\]\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        times = [re.sub(\"[\\[\\]]\", \"\", x.strip())\n",
    "                 for x in lines if re.match(regex, x)]\n",
    "        start, end = times[0], times[-1]\n",
    "\n",
    "        start_time, end_time = datetime.strptime(\n",
    "            start, \"%a %b %d %H:%M:%S %Y\"), datetime.strptime(end, \"%a %b %d %H:%M:%S %Y\")\n",
    "\n",
    "        return end_time - start_time, 32\n",
    "\n",
    "# parse_sunbeam(\"/Volumes/TBHD_share/valencia/pipelines/microbio_spectrum/CLEANED/pipelines/sunbeam4/sunbeam.log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_times(log_paths: OutputLogs) -> TimeData:\n",
    "    \"\"\" Parses all time data, returns a TimeData object.\"\"\"\n",
    "    time_per_cpu = TimeData()\n",
    "    raw_times = TimeData()\n",
    "    # threads_data = ThreadData()\n",
    "\n",
    "    # Parse bio3 time.\n",
    "    # bio3_time, threads = parse_bio_time(log_paths.bio3)\n",
    "    # times.bio3 = bio3_time / threads\n",
    "    # threads_data.bio3 = threads\n",
    "    # Parse bio4 time.\n",
    "    bio4_time, threads = parse_bio_time(log_paths.bio4)\n",
    "    raw_times.bio4 = bio4_time\n",
    "    time_per_cpu.bio4 = bio4_time / threads\n",
    "    # threads_data.bio4 = threads\n",
    "    # Parse JAMS time.\n",
    "    jams_times, threads = parse_jams_time(log_paths.jams)\n",
    "    raw_times.jams = jams_times\n",
    "    time_per_cpu.jams = jams_times / threads\n",
    "    # threads_data.jams = threads\n",
    "    # Parse WGSA2 time.\n",
    "    # wgsa2_time, threads = parse_wgsa2(log_paths.wgsa2)\n",
    "    # times.wgsa2 = wgsa2_time / threads\n",
    "    # # threads_data.wgsa2 = threads\n",
    "    # # Parse Woltka time.\n",
    "    # woltka_times = parse_woltka_time(log_paths.woltka)\n",
    "    # # Woltka used 16 threads. This could be automated but since we are doing just this one pipeline, it's fine.\n",
    "    # times.woltka = woltka_times / 16\n",
    "\n",
    "    sunbeam_times = parse_sunbeam(log_paths.sunbeam)\n",
    "    raw_times.sunbeam = sunbeam_times[0]\n",
    "    time_per_cpu.sunbeam = sunbeam_times[0] / sunbeam_times[1]\n",
    "\n",
    "    return time_per_cpu, raw_times\n",
    "\n",
    "\n",
    "def save_raw_time(raw_time: TimeData, community_name: str):\n",
    "    \"\"\" Saves the raw time data to a file after converting to HH:MM:SS \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(asdict(raw_time), index=[0])\n",
    "\n",
    "    df = df.applymap(lambda x: str(x).split(\".\")[0])\n",
    "\n",
    "    df.index = [community_name]\n",
    "\n",
    "    df.to_csv(os.path.join(\"raw_time.csv\"), mode='a')\n",
    "\n",
    "\n",
    "def analyze_times(log_paths: OutputLogs, community_name: str):\n",
    "    time_per_cpu, raw_time = parse_all_times(log_paths)\n",
    "\n",
    "    save_raw_time(raw_time, community_name)\n",
    "\n",
    "    time_df = pd.DataFrame(asdict(time_per_cpu), index=[0])\n",
    "    # Drop the second row.\n",
    "    time_df.drop([\"bio3\", \"wgsa2\", \"woltka\"], axis=1, inplace=True)\n",
    "\n",
    "    # display(time_df)\n",
    "\n",
    "    # Relative difference is (x2 - min) / min\n",
    "    relative_times = time_df.apply(lambda x: (\n",
    "        x - time_df.min(axis=1)) / time_df.min(axis=1) * 100)\n",
    "\n",
    "    # Set index value to be: \"Relative Time (Factor of Smallest Time)\"\n",
    "    relative_times.index = [\"Relative Time Per CPU (%)\"]\n",
    "\n",
    "    return time_df, relative_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio4</th>\n",
       "      <th>jams</th>\n",
       "      <th>sunbeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tourlousse</th>\n",
       "      <td>00:02:26</td>\n",
       "      <td>00:02:35</td>\n",
       "      <td>00:03:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bio4      jams   sunbeam\n",
       "tourlousse  00:02:26  00:02:35  00:03:49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio4</th>\n",
       "      <th>jams</th>\n",
       "      <th>sunbeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hilo</th>\n",
       "      <td>00:02:05</td>\n",
       "      <td>00:01:57</td>\n",
       "      <td>00:01:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bio4      jams   sunbeam\n",
       "hilo  00:02:05  00:01:57  00:01:11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio4</th>\n",
       "      <th>jams</th>\n",
       "      <th>sunbeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixed</th>\n",
       "      <td>00:02:11</td>\n",
       "      <td>00:02:48</td>\n",
       "      <td>00:01:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bio4      jams   sunbeam\n",
       "mixed  00:02:11  00:02:48  00:01:17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio4</th>\n",
       "      <th>jams</th>\n",
       "      <th>sunbeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mbarc</th>\n",
       "      <td>00:23:10</td>\n",
       "      <td>00:44:14</td>\n",
       "      <td>01:17:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bio4      jams   sunbeam\n",
       "mbarc  00:23:10  00:44:14  01:17:57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/_2115q192kx7c1z764lwhkth898844/T/ipykernel_16916/1740234926.py:36: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  final_df.to_latex(\"time_table.tex\", index=True, escape=True)\n"
     ]
    }
   ],
   "source": [
    "paths_dict = {\n",
    "    # \"nist\": \"/Volumes/TBHD_share/valencia/pipelines/NIST/\"\n",
    "    \"tourlousse\": \"/Volumes/TBHD_share/valencia/pipelines/microbio_spectrum/CLEANED/pipelines/\",\n",
    "    \"hilo\": \"/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/hilo/\",\n",
    "    \"mixed\": \"/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/\",\n",
    "    \"mbarc\": \"/Volumes/TBHD_share/valencia/pipelines/MBARC/pipelines/\"\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    if os.path.exists(\"raw_time.csv\"):\n",
    "        os.remove(\"raw_time.csv\")\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    for k in paths_dict.keys():\n",
    "        log_paths = search_for_files(paths_dict[k])\n",
    "        # print(log_paths)\n",
    "\n",
    "        time_df, relative_time_df = analyze_times(log_paths, k)\n",
    "\n",
    "        # display(time_df)\n",
    "\n",
    "        # Format timedf to HH:MM:SS\n",
    "        time_df = time_df.applymap(lambda x: str(x).split(\".\")[0])\n",
    "\n",
    "        # Strip the days from the raw time_df.\n",
    "        time_df = time_df.applymap(lambda x: x.split(\" \")[-1])\n",
    "        time_df.index = [k]\n",
    "\n",
    "        # Concat the two dataframes.\n",
    "        final_df = pd.concat([time_df, final_df], axis=0)\n",
    "\n",
    "        display(time_df)\n",
    "\n",
    "    final_df.to_latex(\"time_table.tex\", index=True, escape=True)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
