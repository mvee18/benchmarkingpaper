{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "taxonomy_dict = {\"s\": \"species\", \"g\": \"genus\", \"f\": \"family\", \"o\": \"order\", \"c\": \"class\", \"p\": \"phylum\", \"k\": \"kingdom\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/TBHD_share/valencia/pipelines/bmock12/biobakery4/metaphlan/main/species_relab.txt\"\n",
    "# data_path = \"pipelines/bmock12/biobakery4/species_relab.txt\"\n",
    "output_dir = \"pipelines/bmock12/biobakery4\"\n",
    "if not os.path.exists(data_path):\n",
    "    raise Exception(\"Data file does not exist!\")\n",
    "# data_path = \"pipelines/bmock12/biobakery4/species_relab.txt\"\n",
    "data = pd.read_csv(data_path, sep=\"\\t\", index_col=0, usecols=[0,1,2])\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want a csv file with genus, relative abundance.\n",
    "def clean_biobakery(df, rank=\"g\"):\n",
    "    data = df.copy()\n",
    "\n",
    "    # Get the indices so we can split then. They are of the form ex: ...|g__Bacteroides|s__Bacteroides_vulgatus\n",
    "    indices = data.index.to_list()\n",
    "    # Tax_ids are of the form #|#|# ...\n",
    "    tax_ids = data[\"TAX_ID\"].to_list()\n",
    "\n",
    "    # This makes a list of lists, where each sublist is the taxonomy split by the rank.\n",
    "    splitted = [i.split(\"|\") for i in indices]\n",
    "    splitted_ids = [i.split(\"|\") for i in tax_ids]\n",
    "\n",
    "    new_index = []\n",
    "    new_ids = []\n",
    "    # Traverse all of the rows.\n",
    "    for c, i in enumerate(splitted):\n",
    "        # Traverse the sublists.\n",
    "        for c2, j in enumerate(i):\n",
    "            # If it matches the rank we want, then append it to the new index.\n",
    "            if j.startswith(f\"{rank}__\"):\n",
    "                new_index.append(j.replace(f\"{rank}__\", \"\"))\n",
    "                # The taxid is the same index as the taxonomy.\n",
    "                new_ids.append(splitted_ids[c][c2])\n",
    "\n",
    "    # Set the new index.\n",
    "    data.index = new_index\n",
    "\n",
    "    # Make a new dataframe with the new index and the new_ids. We will use this to merge since we do not want to sum the tax_ids.\n",
    "    taxid_df = pd.DataFrame(index=new_index, data=new_ids, columns=[\"TAX_ID\"])\n",
    "\n",
    "    # Sum the rows where the genus/species is the same.\n",
    "    grouped = data.groupby(data.index).sum(numeric_only=True)\n",
    "\n",
    "    # Now, we want to rename the columns to be the sample names, since they are of the form sampleid_###.\n",
    "    columns = grouped.columns.to_list()\n",
    "    new_cols = [i.split(\"_\")[0] for i in columns]\n",
    "    grouped.columns = new_cols\n",
    "\n",
    "    # Divide all the values by 100.\n",
    "    grouped = grouped / 100\n",
    "\n",
    "    # We should now remove duplicates in the taxIDs (since genera can be equivalent). \n",
    "    # If there are duplicates, then we should make it equal to the first value.\n",
    "    taxid_df = taxid_df[~taxid_df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "\n",
    "    return grouped, taxid_df\n",
    "\n",
    "# We want to save to csv, but we want a csv for each column.\n",
    "def save_to_csv(df, taxid_df, output_path, rank=\"s\"):\n",
    "    # Get the columns.\n",
    "    columns = df.columns.to_list()\n",
    "\n",
    "    # Iterate over the columns.\n",
    "    for c, i in enumerate(columns):\n",
    "        # Get the column.\n",
    "        col = df[[i]]\n",
    "\n",
    "        # Join the tax_ids to the column.\n",
    "        # Now, we want to add the new_ids to the dataframe by joining on the index.\n",
    "        col = col.join(taxid_df, how=\"left\")\n",
    "\n",
    "        display(col.head())\n",
    "\n",
    "        # Save to csv.\n",
    "        col.to_csv(os.path.join(output_path, f\"{i.upper()}_{taxonomy_dict[rank]}_relabund_annotated.csv\"), index_label=f\"{rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code\n",
    "Run the below function for cleaning of biobakery. Change rank for the desired rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>TAX_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cohaesibacter_sp_ES_047</th>\n",
       "      <td>0.193621</td>\n",
       "      <td>1798205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Halomonas_sp_HL_48</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>1479235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micromonospora_echinaurantiaca</th>\n",
       "      <td>0.016624</td>\n",
       "      <td>47857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micromonospora_echinofusca</th>\n",
       "      <td>0.020119</td>\n",
       "      <td>47858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muricauda_lutimaris</th>\n",
       "      <td>0.005349</td>\n",
       "      <td>475082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      s1   TAX_ID\n",
       "Cohaesibacter_sp_ES_047         0.193621  1798205\n",
       "Halomonas_sp_HL_48              0.000401  1479235\n",
       "Micromonospora_echinaurantiaca  0.016624    47857\n",
       "Micromonospora_echinofusca      0.020119    47858\n",
       "Muricauda_lutimaris             0.005349   475082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank = \"s\"\n",
    "output, taxid_df = clean_biobakery(data, rank=rank)\n",
    "save_to_csv(df = output, taxid_df = taxid_df, output_path = output_dir, rank=rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
