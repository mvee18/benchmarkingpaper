{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from biom.table import Table\n",
    "# from biom import load_table\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from utils.ncbi.names import generate_names_df, names_db_path, standardize_core\n",
    "from utils.ncbi.jams_convert import fix_name, convert_jams_to_taxid\n",
    "from utils.data_paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The genus was changed, but the Amos paper uses the original genus name.\n",
    "# replacement_dict = {\"Anaerobutyricum hallii\": \"Eubacterium hallii\", \"Anaerobutyricum\": \"Eubacterium\"}\n",
    "# For the Amos paper, the genus was changed to Eubacterium. This is the only result, so we can just replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_wgsa(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Standardizes the WGSA data using the standardize_core function.\n",
    "    \"\"\"\n",
    "    names_df = generate_names_df(names_db_path, load_pickle=True)\n",
    "\n",
    "    # We can use the convert_jams_to_taxid function from the utils.ncbi.convert_jams since the format is the same.\n",
    "    ann, unann = convert_jams_to_taxid(df.head(50), names_df)\n",
    "\n",
    "    return ann, unann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_dict = {\"Genus\": \"G\", \"Species\": \"S\", \"Family\": \"F\", \"Order\": \"O\", \"Class\": \"C\", \"Phylum\": \"P\", \"Kingdom\": \"K\"}\n",
    "\n",
    "def clean_and_parse_wgsa(data_path, output_dir, rank=\"Genus\", left_prefix=\"\"):\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\", header=None, usecols=[1, 3, 4, 5])\n",
    "\n",
    "    # Split off the first two rows. The sum of the unclassified and root counts is the total.\n",
    "    total_counts = df.iloc[:2, 0].sum()\n",
    "\n",
    "    # We need an OR statement to get the unclassified.\n",
    "    df = df.loc[(df[3] == tax_dict[rank]) | (df[3] == \"U\")]\n",
    "    # df = df.where(df[3] == tax_dict[rank]).dropna()\n",
    "\n",
    "    df.sort_values(by=1, ascending=False, inplace=True)\n",
    "\n",
    "    clean_genus = df[[5, 1, 4]].copy(deep=True)\n",
    "    clean_genus.columns = [rank, \"RA\", \"TAX_ID\"]\n",
    "\n",
    "\n",
    "    # Convert the RA column from counts to RA.\n",
    "    clean_genus[\"RA\"] = clean_genus[\"RA\"].apply(lambda x: x / total_counts)\n",
    "\n",
    "    clean_genus.set_index(rank, inplace=True)\n",
    "\n",
    "    # The unclassified tax_id is actually 12908, not 0.\n",
    "    clean_genus.loc[\"unclassified\", \"TAX_ID\"] = 12908\n",
    "\n",
    "    indices = clean_genus.index\n",
    "\n",
    "    indices = [i.lstrip() for i in indices]\n",
    "    \n",
    "    # Remove any [ and ] characters from the indices.\n",
    "    indices = [i.replace(\"[\", \"\") for i in indices]\n",
    "    indices = [i.replace(\"]\", \"\") for i in indices]\n",
    "\n",
    "    clean_genus.index = indices\n",
    "\n",
    "    # Since the WGSA data already contains the TAXID, it is much faster than this function.\n",
    "    # ann, uann = standardize_wgsa(clean_genus)\n",
    "\n",
    "    clean_genus = clean_genus.astype({\"TAX_ID\": int})\n",
    "\n",
    "    prefix = os.path.basename(data_path).split(\"_\")[0]\n",
    "    # left_prefix = \"s\"\n",
    "    output_file = os.path.join(output_dir, left_prefix + prefix.upper() + \"_\" + rank.lower() + \"_\" + \"relabund_annotated.csv\")\n",
    "\n",
    "    clean_genus.to_csv(output_file, sep=\",\", header=True, index_label=rank)\n",
    "\n",
    "# clean_and_parse_wgsa(cami_sim_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be more than one output file, so we need to combine them.\n",
    "def combine_files(data_path: str, rank: str, output_dir: str, prefix: str = \"\"):\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\"The data path does not exist.\")\n",
    "\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        print(files)\n",
    "        if len(files) == 0:\n",
    "            raise Exception(\"No files found in output directory.\")\n",
    "            \n",
    "        for file in files:\n",
    "            if \"REPORT\" in file:\n",
    "                print(os.path.join(root, file))\n",
    "                clean_and_parse_wgsa(os.path.join(root, file), output_dir, rank=rank, left_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mix-D_taxREPORT.txt', 'EG_taxREPORT.txt', 'Neg_taxREPORT.txt', 'Mix-A_taxREPORT.txt', 'Mix-B_taxREPORT.txt', 'Mix-C_taxREPORT.txt']\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-D_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/EG_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Neg_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-A_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-B_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-C_taxREPORT.txt\n",
      "['Mix-D_taxREPORT.txt', 'EG_taxREPORT.txt', 'Neg_taxREPORT.txt', 'Mix-A_taxREPORT.txt', 'Mix-B_taxREPORT.txt', 'Mix-C_taxREPORT.txt']\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-D_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/EG_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Neg_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-A_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-B_taxREPORT.txt\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/Mix-C_taxREPORT.txt\n"
     ]
    }
   ],
   "source": [
    "def run_wgsa_clean():\n",
    "    paths = make_data_list()\n",
    "    for p in paths:\n",
    "        prefix = \"\"\n",
    "        # Skip if the data doesn't exist.\n",
    "        if p.wgsa == \"\":\n",
    "            continue\n",
    "            \n",
    "        if \"bmock12\" in p.path or \"camisim\" in p.path:\n",
    "            prefix = \"S\"\n",
    "        else:\n",
    "            prefix = \"\"\n",
    "\n",
    "        # Remove this to do all the directories \n",
    "        if \"nist\" in p.path:\n",
    "            out_path = os.path.join(p.path, \"wgsa\")\n",
    "            if os.path.exists(out_path):\n",
    "                combine_files(p.wgsa, \"Genus\", out_path, prefix)\n",
    "                combine_files(p.wgsa, \"Species\", out_path, prefix)\n",
    "            else:\n",
    "                out_path = os.path.join(p.path, \"wgsa2\")\n",
    "                combine_files(p.wgsa, \"Genus\", out_path, prefix)\n",
    "                combine_files(p.wgsa, \"Species\", out_path, prefix)\n",
    "\n",
    "run_wgsa_clean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
