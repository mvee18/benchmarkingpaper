{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from utils.ncbi.jams_convert import convert_jams_to_taxid, generate_names_df, names_db_path\n",
    "from utils.data_paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\"LKT__s__Anaerobutyricum_hallii\": \"LKT__s__Eubacterium_hallii\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update replacement dict for JAMS.\n",
    "\n",
    "camisim_replacement_dict = {\n",
    "    \"Acetivibrio_thermocellus\": \"Ruminiclostridium_thermocellum\", \n",
    "    \"Thermoclostridium_stercorarium\": \"Ruminiclostridium_stercorarium\",\n",
    "}\n",
    "\n",
    "def clean_jams(input_file: str, rank: str = \"Genus\", input_type=\"csv\"):\n",
    "    \"\"\"\n",
    "    This function cleans the output from JAMSalpha in the bmock12 dataset. From now on, use the JAMSbeta function.\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = os.path.dirname(input_file)\n",
    "    file_name = os.path.basename(input_file).split(\".\")[0]\n",
    "    csv_path = os.path.join(output_dir, f\"{file_name.upper()}_{rank.lower()}_relabund.csv\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    if input_type == \"csv\":\n",
    "        df = pd.read_csv(input_file, index_col=0)\n",
    "    elif input_type == \"excel\":\n",
    "        df = pd.read_excel(input_file, index_col=0)\n",
    "    else:\n",
    "        raise Exception(\"Input type not recognized.\")\n",
    "    \n",
    "    df[\"RA\"] = df[\"NumBases\"] / df[\"NumBases\"].sum()\n",
    "    # display(df.head())\n",
    "    species_df = df[[\"Species\", \"RA\"]].groupby(\"Species\").sum()\n",
    "    species_df.sort_values(\"RA\", ascending=False, inplace=True)\n",
    "\n",
    "    # We need to remove g__ and s__ from the index names\n",
    "    # genus_df.index = genus_df.index.str.replace(\"g__\", \"\")\n",
    "    species_df.index = species_df.index.str.replace(\"s__\", \"\")\n",
    "\n",
    "    names_df = generate_names_df(names_db_path, load_pickle=True)\n",
    "\n",
    "    if rank == \"Genus\":\n",
    "        # We need to split the species names into genus and species on the _ character.\n",
    "        species_names = species_df.index.to_list()\n",
    "        genus_names = [x.split(\"_\")[0] for x in species_names]\n",
    "\n",
    "        species_df[\"Genus\"] = genus_names\n",
    "\n",
    "        genus_df = species_df[[\"Genus\", \"RA\"]].groupby(\"Genus\").sum()\n",
    "\n",
    "        genus_df.sort_values(\"RA\", ascending=False, inplace=True)\n",
    "\n",
    "        # genus_df.to_csv(csv_path)\n",
    "\n",
    "        annotated, unannotated = convert_jams_to_taxid(genus_df, names_df)\n",
    "        annotated.to_csv(csv_path.replace(\".csv\", \"_annotated.csv\"), index_label=rank)\n",
    "\n",
    "        return\n",
    "\n",
    "    annotated, unannotated = convert_jams_to_taxid(species_df, names_df)\n",
    "    annotated.to_csv(csv_path.replace(\".csv\", \"_annotated.csv\"), index_label=rank)\n",
    "\n",
    "# clean_jams(input_file = \"pipelines/camisimGI/jams/s1.csv\", rank = \"Genus\", input_type = \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jams_to_csv(df: pd.DataFrame, taxid_df: pd.DataFrame, output_dir: str, rank: str):\n",
    "    # Save each column as a separate file.\n",
    "    columns = df.columns.to_list()\n",
    "    for c, i in enumerate(columns):\n",
    "        col = df[[i]]\n",
    "        col = col.join(taxid_df, how=\"left\")\n",
    "\n",
    "        col.astype({\"tax_id\": \"int64\"})\n",
    "\n",
    "        col.sort_values(i, ascending=False, inplace=True)\n",
    "\n",
    "        col.to_csv(os.path.join(output_dir, f\"{i.upper()}_{rank}_relabund_annotated.csv\"), index_label=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jams_beta(input_file: str, rank=\"genus\", output_dir=\"\"):\n",
    "    \"\"\"Clean JAMS output excel file and save them in the preferred format. \n",
    "    It will generate a separate file for each sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dir : str\n",
    "        Path to directory containing JAMS output files.\n",
    "    rank : str\n",
    "        Taxonomic rank.\n",
    "    output_dir : str\n",
    "        Path to directory where output files will be saved.\n",
    "    \"\"\"\n",
    "    print(input_file)\n",
    "    df = pd.read_excel(input_file, index_col=0, sheet_name=1)\n",
    "    # Make everything into relative abundances (i.e. pct).\n",
    "    df = df / df.sum(axis=0)\n",
    "    # Convert PPM to percentage. This does the same as above.\n",
    "    # df = df / 10000\n",
    "\n",
    "    # We need to find anything with s__ or g__ in the row.names.\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # If s__ is in the name, we need to get the genus name.\n",
    "    index_names = []\n",
    "    if rank == \"genus\":\n",
    "        df = df.where(df[\"row.names\"].str.contains(\"g__|s__|Unclassified\")).dropna()\n",
    "        lkt = df[\"row.names\"].to_list()\n",
    "        for i in lkt:\n",
    "            if \"s__\" in i:\n",
    "                index_names.append(i.split(\"s__\")[1].split(\"_\")[0])\n",
    "            elif \"g__\" in i:\n",
    "                index_names.append(i.split(\"g__\")[1].split(\"_\")[0])\n",
    "            else:\n",
    "                # Then it is LKT__Unclassified, so we need to remove the LKT__.\n",
    "                index_names.append(i.split(\"LKT__\")[1])\n",
    "\n",
    "    elif rank == \"species\":\n",
    "        df = df.where(df[\"row.names\"].str.contains(\"s__|Unclassified\")).dropna()\n",
    "        lkt = df[\"row.names\"].to_list()\n",
    "        for i in lkt:\n",
    "            if \"s__\" in i:\n",
    "                index_names.append(i.split(\"s__\")[1])\n",
    "            else:\n",
    "                print(i)\n",
    "                # Then it is LKT__Unclassified, so we need to remove the LKT__.\n",
    "                index_names.append(i.split(\"LKT__\")[1])\n",
    "            \n",
    "        index_names = [i.replace(\"_\", \" \") for i in index_names]\n",
    "\n",
    "\n",
    "    df.index = index_names\n",
    "    df.drop(columns=[\"row.names\"], inplace=True)\n",
    "\n",
    "    # Sum all of the rows with the same index name.\n",
    "    df = df.groupby(df.index).sum()\n",
    "\n",
    "    names_df = generate_names_df(names_db_path, load_pickle=True)\n",
    "    annotated, unannotated = convert_jams_to_taxid(df.copy(), names_df)\n",
    "\n",
    "    # We want to split off the tax_ids so we can save each column as a separate csv. \n",
    "    # Otherwise, we will save the tax_ids as a separate csv.\n",
    "    taxid_df = annotated[[\"tax_id\"]]\n",
    "    annotated.drop(columns=[\"tax_id\"], inplace=True)\n",
    "\n",
    "    save_jams_to_csv(annotated, taxid_df, output_dir, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jams_beta_higher(path: str):\n",
    "    # First, read in the data.\n",
    "    df_ppm = pd.read_excel(path, index_col=0, sheet_name=1)\n",
    "    # Convert the PPM to percentages.\n",
    "    df_pct = df_ppm / 10000\n",
    "\n",
    "    df_tax = pd.read_excel(path, index_col=0, sheet_name=4)\n",
    "\n",
    "    # Add a column to df_pct that is the phylum from df_tax. \n",
    "    # The row numbers are the same, so we can just use the index.\n",
    "    # df_pct[\"Phylum\"] = df_tax[\"Phylum\"]\n",
    "    \n",
    "    # We can also join on the index to combined relabund and taxonomy.\n",
    "    df_pct = df_pct.join(df_tax, how=\"inner\")\n",
    "\n",
    "    output_path = os.path.join(os.path.dirname(path), f\"taxonomy_relabund.csv\")\n",
    "\n",
    "    df_pct.to_csv(output_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/jams/beta_output/NIST_Relabund_PPM.xlsx\n",
      "The pkl file was last modified (and hopefully generated) on 2022-10-27 14:39:35+00:00\n",
      "/Volumes/TBHD_share/valencia/pipelines/NIST/pipelines/jams/beta_output/NIST_Relabund_PPM.xlsx\n",
      "LKT__Unclassified\n",
      "The pkl file was last modified (and hopefully generated) on 2022-10-27 14:39:35+00:00\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "# rank = \"species\"\n",
    "paths = make_data_list()\n",
    "for p in paths:\n",
    "    # Bmock12 did not need to be resubmitted.\n",
    "    if \"bmock12\" in p.path:\n",
    "        # Bmock12 already has the unclassifieds added.\n",
    "        continue\n",
    "\n",
    "    if \"nist\" in p.path:\n",
    "        clean_jams_beta(p.jams, rank=\"genus\", output_dir=os.path.join(p.path, \"jams\"))\n",
    "        clean_jams_beta(p.jams, rank=\"species\", output_dir=os.path.join(p.path, \"jams\"))\n",
    "\n",
    "    # if p.jams != \"\":\n",
    "        # clean_jams_beta(p.jams, rank=\"genus\", output_dir=os.path.join(p.path, \"jams\"))\n",
    "        # clean_jams_beta(p.jams, rank=\"species\", output_dir=os.path.join(p.path, \"jams\"))\n",
    "\n",
    "\n",
    "# data_path = hmpTongue.jams\n",
    "# output_dir = \"pipelines/hmp/tongue/jams\"\n",
    "\n",
    "# clean_jams_beta(data_path, rank=\"species\", output_dir=output_dir)\n",
    "# clean_jams_beta(data_path, rank=\"genus\", output_dir=output_dir)\n",
    "# clean_jams_beta_higher(\"/Volumes/NRTS_share/SMS_NIAID_0162/fqfiles/Batch1/jams/brain_jams/brainjams_Relabund_PPM.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
