{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import pandas as pd\n",
    "from python_src.figures_utils import get_all_expected, generate_experimental_df, get_relabund_files, fully_combined, generate_cb\n",
    "from dataclasses import dataclass\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    This class will hold the parameters for each pipeline.\n",
    "    Variables:\n",
    "        root: str\n",
    "            The root directory of the pipeline.\n",
    "        inset: bool\n",
    "            Whether or not to include an inset plot.\n",
    "    \"\"\"\n",
    "    root: str\n",
    "    inset: bool\n",
    "\n",
    "    def __init__(self, root: str, inset: bool):\n",
    "        self.root = root\n",
    "        self.inset = inset\n",
    "\n",
    "tourlousse = Pipeline(\"../../pipelines/tourlousse\", False)\n",
    "amos_hilo = Pipeline(\"../../pipelines/amos/hilo\", False)\n",
    "amos_mixed = Pipeline(\"../../pipelines/amos/mixed\", False)\n",
    "\n",
    "experiments = [tourlousse, amos_hilo, amos_mixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_x_labels(ax, df, rank):\n",
    "    xticks = ax.get_xticklabels()\n",
    "    # print(xticks)\n",
    "    new_labels = []\n",
    "    for x in xticks:\n",
    "        # res = df.loc[int(x.get_text()), rank]\n",
    "        res = df.loc[df[\"TAX_ID\"] == int(x.get_text()), rank]\n",
    "        # Get only the first row from the series.\n",
    "        # This is necessary because if it is unique, it will return a string, but if it is not unique, it will return a series.\n",
    "        if isinstance(res, pd.Series):\n",
    "            res = res.iloc[0]\n",
    "        new_labels.append(res)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cb_palette = generate_cb()\n",
    "\n",
    "def make_title(rank: str, exp_name: str, thresh: float):\n",
    "    return f\"Average Relative Abundance of {rank.capitalize()} in Experiement {exp_name.capitalize()} at Threshold {thresh}\"\n",
    "\n",
    "def plot_bars(thresh: float, rank: str = \"genus\"):\n",
    "    for e in experiments:\n",
    "        # Initialize the dataframe to hold the data.\n",
    "        plt_df = pd.DataFrame()\n",
    "        # Make the bigger figure.\n",
    "        fig = plt.figure(figsize=(15, 12))\n",
    "\n",
    "        exp_name = e.root.split(\"/\")[-1]\n",
    "\n",
    "        # Get the data for the experiment.\n",
    "        fc = fully_combined(e.root, rank)\n",
    "\n",
    "        # Only select where Source is \"expected\", \"bio4\", or \"jams202212\".\n",
    "        fc = fc.loc[fc[\"Source\"].isin([\"Expected\", \"biobakery4\", \"jams202212\"])]\n",
    "        fc.to_csv(f\"{rank}_{exp_name}_fc.csv\", index=True)\n",
    "\n",
    "        continue\n",
    "\n",
    "        for pl, pl_df in fc.groupby(\"Source\"):\n",
    "            # Average the abundances on the same index values. This keeps the names of the taxa.\n",
    "            averaged_df = pl_df.groupby([\"TAX_ID\", rank, \"Source\"]).mean(numeric_only=True)\n",
    "\n",
    "            # Filter out the values that are below the threshold.\n",
    "            averaged_df = averaged_df.loc[averaged_df[\"RA\"] > thresh]\n",
    "\n",
    "            # Add the data to the plot dataframe.\n",
    "            plt_df = pd.concat([plt_df, averaged_df], axis=0)\n",
    "\n",
    "            # pl_df.to_csv(f\"genus_{pl}.csv\", index=True)\n",
    "\n",
    "        plt_df.reset_index(inplace=True)        \n",
    "\n",
    "        # We want only bio4 and jams.\n",
    "        plt_df = plt_df.loc[plt_df[\"Source\"].isin([\"Expected\", \"bio4\", \"jams\"])]\n",
    "\n",
    "        # Plot the data.\n",
    "        ax = sns.barplot(x=\"TAX_ID\", y='RA', hue=\"Source\", data=plt_df, errorbar=None, log=True, palette=cb_palette)\n",
    "        ax.set_xticklabels(fix_x_labels(ax=ax, df=plt_df, rank=rank), rotation=45, horizontalalignment='right')\n",
    "\n",
    "        # Make the title and add the axes labels.\n",
    "        ax.set_title(make_title(rank, exp_name, thresh))\n",
    "        ax.set_xlabel(rank.capitalize())\n",
    "        ax.set_ylabel('Average Relative Abundance')\n",
    "\n",
    "        # Save the plt_df.\n",
    "        # plt_df.to_csv(f\"{rank}_{exp_name}_{thresh}.csv\", index=False)\n",
    "\n",
    "plot_bars(0.0001, \"species\")\n",
    "plot_bars(0.0001, \"genus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/valenciaem/coding/pipelines/utils/analysis/all_stats_genus.csv\n",
      "/Users/valenciaem/coding/pipelines/utils/analysis/all_stats_species.csv\n"
     ]
    }
   ],
   "source": [
    "# Creation of Statistical Analysis Plots\n",
    "stats_path_genus = os.path.abspath(\"../../utils/analysis/all_stats_genus.csv\")\n",
    "stats_path_species = os.path.abspath(\"../../utils/analysis/all_stats_species.csv\")\n",
    "stats_paths = [stats_path_genus, stats_path_species]\n",
    "\n",
    "def non_avg_stats():\n",
    "    for stats_path in stats_paths:\n",
    "        stats_df = pd.DataFrame()\n",
    "        print(stats_path)\n",
    "        df = pd.read_csv(stats_path)\n",
    "        df = df.loc[(df[\"Source\"] == \"tourlousse\") | (df[\"Source\"] == \"mixed\") | (df[\"Source\"] == \"hilo\")]\n",
    "        df = df.loc[(df[\"Pipeline\"] == \"biobakery4\") | (df[\"Pipeline\"] == \"jams202212\")]\n",
    "        df = df.loc[(df[\"threshold\"] == 0.0001)]\n",
    "        for src, src_df in df.groupby(\"Source\"):\n",
    "            # display(src_df)\n",
    "            # fig = plt.figure(figsize=(15, 12))\n",
    "            # g = sns.catplot(x=\"SampleID\", y=\"AD\", hue=\"Pipeline\", data=src_df, kind=\"box\", palette=cb_palette)\n",
    "            # plt.show()\n",
    "            # sns.barplot(x=\"SampleID\", y=\"AD\", hue=\"Pipeline\", data=src_df, palette=cb_palette)\n",
    "            for pl, pl_df in src_df.groupby(\"Pipeline\"):\n",
    "                # pl_df.loc[\"Average\"] = pl_df.mean(numeric_only=True)\n",
    "                avg = pl_df.mean(numeric_only=True)\n",
    "                std = pl_df.std(numeric_only=True)\n",
    "\n",
    "                avg_cols = avg.keys()\n",
    "                avg_cols = [\"Pipeline\", \"Community\"] + avg_cols.to_list()\n",
    "\n",
    "                new_line = [f\"{val:.2f} ± {std[c]:.2f}\" for c, val in enumerate(avg)]\n",
    "                new_line.insert(0, src)\n",
    "                new_line.insert(0, pl)\n",
    "                # print(new_line)\n",
    "                stats_df = pd.concat([stats_df, pd.DataFrame(new_line, index=avg_cols).T])\n",
    "\n",
    "                # stats_df = pd.concat([stats_df, avg])\n",
    "                # stats_df = pd.concat([stats_df, std])\n",
    "                # pl_df.loc[\"Stddev\"] = pl_df.std(numeric_only=True)\n",
    "                # pl_df.loc[\"Stddev\"] = pl_df.std(numeric_only=True)\n",
    "                # display(pl_df)\n",
    "        # display(stats_df)\n",
    "        rank = stats_path.split(\"/\")[-1].split(\"_\")[2].split(\".\")[0]\n",
    "        stats_df.to_csv(f\"{rank}_stats.csv\", index=False)\n",
    "    \n",
    "non_avg_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_subset = \"../../utils/analysis/all_stats_species_subset.csv\"\n",
    "genus_subset = \"../../utils/analysis/all_stats_genus_subset.csv\"\n",
    "data_subset = [species_subset, genus_subset]\n",
    "\n",
    "cols = [\"SampleID\", \"Diversity\", \"R^2\", \"MAE\", \"AD\", \"1-BC\", \"RMSE\", \"Sens\", \"FPRA\", \"Pipeline\", \"threshold\", \"Source\", \"Run\"]\n",
    "\n",
    "\n",
    "def average_jams_runs():\n",
    "    for data_path in data_subset:\n",
    "        stats_df_avg = pd.DataFrame()\n",
    "        df = pd.read_csv(data_path, names=cols)\n",
    "        for src, src_df in df.groupby(\"Source\"):\n",
    "            pl_avg = src_df.groupby(\"Pipeline\").mean(numeric_only=True)\n",
    "            pl_std = src_df.groupby(\"Pipeline\").std(numeric_only=True)\n",
    "\n",
    "            # Items in the same index should be of the format \"val ± std\"\n",
    "            pl_avg = pl_avg[[\"R^2\", \"AD\", \"Sens\", \"FPRA\"]]\n",
    "            pl_std = pl_std[[\"R^2\", \"AD\", \"Sens\", \"FPRA\"]]\n",
    "            for c, col in enumerate(pl_avg.columns):\n",
    "                pl_avg[col] = [f\"{float(val):.2f} ± {float(pl_std[col][c]):.2f}\" for c, val in enumerate(pl_avg[col])]\n",
    "                pl_avg[\"Source\"] = src\n",
    "            \n",
    "            stats_df_avg = pd.concat([stats_df_avg, pl_avg])\n",
    "\n",
    "        if \"genus\" in data_path:\n",
    "            stats_df_avg.to_csv(\"genus_stats_mr.csv\", index=True)\n",
    "        elif \"species\" in data_path:\n",
    "            stats_df_avg.to_csv(\"species_stats_mr.csv\", index=True)\n",
    "        else:\n",
    "            raise Exception(\"Invalid data path\")\n",
    "        display(stats_df_avg)\n",
    "\n",
    "\n",
    "            # display(pd.DataFrame(pl_avg))\n",
    "            # display(pd.DataFrame(pl_std))\n",
    "            # for pl, pl_df in src_df.groupby(\"Pipeline\"):\n",
    "            #     display(pl_df)\n",
    "            #     avg = pl_df.groupby(\"SampleID\").mean(numeric_only=True)\n",
    "            #     display(pd.DataFrame(avg))\n",
    "                # for smpl, smpl_df in pl_df.groupby(\"SampleID\"):\n",
    "                #     avg = smpl_df.mean(numeric_only=True)\n",
    "                #     new_row = pd.DataFrame(avg).T\n",
    "                #     new_row[\"SampleID\"] = smpl\n",
    "                #     new_row[\"Pipeline\"] = pl\n",
    "                #     new_row[\"Source\"] = src\n",
    "                #     display(new_row)\n",
    "\n",
    "        # display(df)\n",
    "\n",
    "# average_jams_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
