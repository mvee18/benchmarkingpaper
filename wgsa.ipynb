{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from biom.table import Table\n",
    "# from biom import load_table\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TEDreadsTAX reports in TAXprofiles/TEDreadsTAX/reports.\n",
    "data = \"/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/hilo/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports\"\n",
    "output_path = \"pipelines/amos/hilo/wgsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_dict = {\"Genus\": \"G\", \"Species\": \"S\", \"Family\": \"F\", \"Order\": \"O\", \"Class\": \"C\", \"Phylum\": \"P\", \"Kingdom\": \"K\"}\n",
    "\n",
    "def clean_and_parse_wgsa(data_path, output_dir, rank=\"Genus\"):\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\", header=None, usecols=[0, 3, 5])\n",
    "    df = df.where(df[3] == tax_dict[rank]).dropna()\n",
    "    df.sort_values(by=0, ascending=False, inplace=True)\n",
    "\n",
    "    clean_genus = df[[5, 0]]\n",
    "    clean_genus.columns = [rank, \"RA\"]\n",
    "    clean_genus[\"RA\"] = clean_genus[\"RA\"] / 100\n",
    "    clean_genus.set_index(rank, inplace=True)\n",
    "\n",
    "    indices = clean_genus.index\n",
    "    indices = [i.lstrip() for i in indices]\n",
    "    clean_genus.index = indices\n",
    "\n",
    "    # clean_genus.head(10)\n",
    "\n",
    "    prefix = os.path.basename(data_path).split(\"_\")[0]\n",
    "    output_file = os.path.join(output_dir, \"s\" + prefix + \"_\" + rank.lower() + \"_\" + \"relabund.csv\")\n",
    "\n",
    "    clean_genus.to_csv(output_file, sep=\",\", header=True, index_label=rank)\n",
    "\n",
    "# clean_and_parse_wgsa(cami_sim_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be more than one output file, so we need to combine them.\n",
    "def combine_files(data_path: str, rank: str):\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\"The data path does not exist.\")\n",
    "\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        print(files)\n",
    "        if len(files) == 0:\n",
    "            raise Exception(\"No files found in output directory.\")\n",
    "            \n",
    "        for file in files:\n",
    "            if \"REPORT\" in file:\n",
    "                print(os.path.join(root, file))\n",
    "                clean_and_parse_wgsa(os.path.join(root, file), output_path, rank=rank)\n",
    "\n",
    "combine_files(data, \"Genus\")\n",
    "combine_files(data, \"Species\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
