{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from biom.table import Table\n",
    "# from biom import load_table\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.ncbi.names import generate_names_df, names_db_path, standardize_core\n",
    "from utils.ncbi.jams_convert import fix_name, convert_jams_to_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TEDreadsTAX reports in TAXprofiles/TEDreadsTAX/reports.\n",
    "data = \"/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports\"\n",
    "output_path = \"pipelines/amos/mixed/wgsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The genus was changed, but the Amos paper uses the original genus name.\n",
    "# replacement_dict = {\"Anaerobutyricum hallii\": \"Eubacterium hallii\", \"Anaerobutyricum\": \"Eubacterium\"}\n",
    "# For the Amos paper, the genus was changed to Eubacterium. This is the only result, so we can just replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_wgsa(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Standardizes the WGSA data using the standardize_core function.\n",
    "    \"\"\"\n",
    "    names_df = generate_names_df(names_db_path, load_pickle=True)\n",
    "\n",
    "    # Let's remove anything below 0.5% (50 ppm). \n",
    "    # There are thousands of features and are taking too much time to annotate.\n",
    "    print(\"Before: \", df.shape)\n",
    "    df = df.where(df[\"RA\"] >= 0.005).dropna()\n",
    "    print(\"After: \", df.shape)\n",
    "\n",
    "    # We can use the convert_jams_to_taxid function from the utils.ncbi.convert_jams since the format is the same.\n",
    "    ann, unann = convert_jams_to_taxid(df.head(50), names_df)\n",
    "\n",
    "    return ann, unann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_dict = {\"Genus\": \"G\", \"Species\": \"S\", \"Family\": \"F\", \"Order\": \"O\", \"Class\": \"C\", \"Phylum\": \"P\", \"Kingdom\": \"K\"}\n",
    "\n",
    "def clean_and_parse_wgsa(data_path, output_dir, rank=\"Genus\", left_prefix=\"\"):\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\", header=None, usecols=[0, 3, 5])\n",
    "    df = df.where(df[3] == tax_dict[rank]).dropna()\n",
    "    df.sort_values(by=0, ascending=False, inplace=True)\n",
    "\n",
    "    clean_genus = df[[5, 0]].copy(deep=True)\n",
    "    clean_genus.columns = [rank, \"RA\"]\n",
    "    clean_genus[\"RA\"] = clean_genus[\"RA\"].apply(lambda x: x / 100)\n",
    "\n",
    "    clean_genus.set_index(rank, inplace=True)\n",
    "\n",
    "    indices = clean_genus.index\n",
    "    indices = [i.lstrip() for i in indices]\n",
    "\n",
    "    # Remove any [ and ] characters from the indices.\n",
    "    indices = [i.replace(\"[\", \"\") for i in indices]\n",
    "    indices = [i.replace(\"]\", \"\") for i in indices]\n",
    "\n",
    "    # Replace any genus names with the correct genus name.\n",
    "    # indices = [replacement_dict[i] if i in replacement_dict else i for i in indices]\n",
    "\n",
    "    clean_genus.index = indices\n",
    "\n",
    "    ann, uann = standardize_wgsa(clean_genus)\n",
    "\n",
    "    # If the shape of uann is not 0, then we have unannotated features.\n",
    "    if uann.shape[0] != 0:\n",
    "        print(\"WARNING: Unannotated features: \", uann.shape[0])\n",
    "        print(uann.head(10))\n",
    "\n",
    "    prefix = os.path.basename(data_path).split(\"_\")[0]\n",
    "    # left_prefix = \"s\"\n",
    "    output_file = os.path.join(output_dir, left_prefix + prefix + \"_\" + rank.lower() + \"_\" + \"relabund.csv\")\n",
    "\n",
    "    ann.to_csv(output_file, sep=\",\", header=True, index_label=rank)\n",
    "\n",
    "# clean_and_parse_wgsa(cami_sim_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SRR11487940_taxREPORT.txt', 'SRR11487939_taxREPORT.txt', 'SRR11487938_taxREPORT.txt', 'SRR11487937_taxREPORT.txt', 'SRR11487941_taxREPORT.txt']\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487940_taxREPORT.txt\n",
      "Before:  (926, 1)\n",
      "After:  (15, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487939_taxREPORT.txt\n",
      "Before:  (917, 1)\n",
      "After:  (15, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487938_taxREPORT.txt\n",
      "Before:  (907, 1)\n",
      "After:  (15, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487937_taxREPORT.txt\n",
      "Before:  (892, 1)\n",
      "After:  (15, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487941_taxREPORT.txt\n",
      "Before:  (916, 1)\n",
      "After:  (15, 1)\n",
      "['SRR11487940_taxREPORT.txt', 'SRR11487939_taxREPORT.txt', 'SRR11487938_taxREPORT.txt', 'SRR11487937_taxREPORT.txt', 'SRR11487941_taxREPORT.txt']\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487940_taxREPORT.txt\n",
      "Before:  (2161, 1)\n",
      "After:  (17, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487939_taxREPORT.txt\n",
      "Before:  (2079, 1)\n",
      "After:  (17, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487938_taxREPORT.txt\n",
      "Before:  (2150, 1)\n",
      "After:  (17, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487937_taxREPORT.txt\n",
      "Before:  (2111, 1)\n",
      "After:  (17, 1)\n",
      "/Volumes/TBHD_share/valencia/pipelines/amos/nibsc/mixed/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports/SRR11487941_taxREPORT.txt\n",
      "Before:  (2154, 1)\n",
      "After:  (17, 1)\n"
     ]
    }
   ],
   "source": [
    "# There may be more than one output file, so we need to combine them.\n",
    "def combine_files(data_path: str, rank: str):\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\"The data path does not exist.\")\n",
    "\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        print(files)\n",
    "        if len(files) == 0:\n",
    "            raise Exception(\"No files found in output directory.\")\n",
    "            \n",
    "        for file in files:\n",
    "            if \"REPORT\" in file:\n",
    "                print(os.path.join(root, file))\n",
    "                clean_and_parse_wgsa(os.path.join(root, file), output_path, rank=rank)\n",
    "\n",
    "combine_files(data, \"Genus\")\n",
    "combine_files(data, \"Species\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
