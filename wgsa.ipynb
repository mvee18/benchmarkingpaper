{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from biom.table import Table\n",
    "from biom import load_table\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/Volumes/TBHD_share/valencia/bmock12/NEPHELE/wgsa2/subset_bmock12/outputs/TAXprofiles/TEDreadsTAX/reports/1_taxREPORT.txt\"\n",
    "cami_sim_data = \"/Volumes/TBHD_share/valencia/pipelines/microbio_spectrum/wgsa/outputs/TAXprofiles/TEDreadsTAX/reports\"\n",
    "output_path = \"pipelines/toulousse/wgsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_dict = {\"Genus\": \"G\", \"Species\": \"S\", \"Family\": \"F\", \"Order\": \"O\", \"Class\": \"C\", \"Phylum\": \"P\", \"Kingdom\": \"K\"}\n",
    "\n",
    "def clean_and_parse_wgsa(data_path, output_dir, rank=\"Genus\"):\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\", header=None, usecols=[0, 3, 5])\n",
    "    df = df.where(df[3] == tax_dict[rank]).dropna()\n",
    "    df.sort_values(by=0, ascending=False, inplace=True)\n",
    "\n",
    "    clean_genus = df[[5, 0]]\n",
    "    clean_genus.columns = [rank, \"RA\"]\n",
    "    clean_genus[\"RA\"] = clean_genus[\"RA\"] / 100\n",
    "    clean_genus.set_index(rank, inplace=True)\n",
    "\n",
    "    indices = clean_genus.index\n",
    "    indices = [i.lstrip() for i in indices]\n",
    "    clean_genus.index = indices\n",
    "\n",
    "    # clean_genus.head(10)\n",
    "\n",
    "    prefix = os.path.basename(data_path).split(\"_\")[0]\n",
    "    output_file = os.path.join(output_dir, \"s\" + prefix + \"_\" + rank.lower() + \"_\" + \"relabund.csv\")\n",
    "\n",
    "    clean_genus.to_csv(output_file, sep=\",\", header=True, index_label=rank)\n",
    "\n",
    "# clean_and_parse_wgsa(cami_sim_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be more than one output file, so we need to combine them.\n",
    "def combine_files(data_path: str, rank: str):\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        if len(files) == 0:\n",
    "            raise Exception(\"No files found in output directory.\")\n",
    "            \n",
    "        for file in files:\n",
    "            if \"REPORT\" in file:\n",
    "                print(os.path.join(root, file))\n",
    "                clean_and_parse_wgsa(os.path.join(root, file), output_path, rank=rank)\n",
    "\n",
    "combine_files(cami_sim_data, \"Genus\")\n",
    "combine_files(cami_sim_data, \"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Old way of doing it.\n",
    "# t = load_table(\"/Volumes/TBHD/Valencia/Microbiome_Analysis/Nephele_cloud_play_project/outputs/for_analyze_with_microbiomedb.biom\")\n",
    "# t = load_table(\"/Volumes/TBHD_share/valencia/3sample/no_merge_trim+trim_output/for_analyze_with_microbiomedb.biom\")\n",
    "# t = load_table(\"/Volumes/TBHD_share/valencia/3sample/batch2/wgsa2/outputs/for_analyze_with_microbiomedb.biom\")\n",
    "# t = load_table(\"/Volumes/TBHD_share/valencia/3sample/batch2/wgsa2/outputs/TAXprofiles/MAGs_TAX/MAG-based_Counts+TAX.biom\")\n",
    "# t = load_table(\"/Volumes/TBHD_share/walitt_sample/3sample/outputs/for_analyze_with_microbiomedb.biom\")\n",
    "t = load_table(\"/Volumes/TBHD_share/valencia/bmock12/NEPHELE/wgsa2/subset_bmock12/outputs/for_analyze_with_microbiomedb.biom\")\n",
    "# print(t)\n",
    "t.ids(axis='observation')\n",
    "# Use 6 for species, 5 for genus.\n",
    "\n",
    "phylum_idx = 6\n",
    "# Somtimes taxonomy is capitalized, sometimes not.\n",
    "collapse_f = lambda id_, md: '; '.join(md['Taxonomy'][phylum_idx:phylum_idx+1])\n",
    "collapsed = t.collapse(collapse_f, axis='observation')\n",
    "\n",
    "df = collapsed.to_dataframe()\n",
    "display(df)\n",
    "\n",
    "col1 = pd.DataFrame(df.iloc[:, :])\n",
    "display(col1)\n",
    "\n",
    "col1 = col1.sparse.to_dense()\n",
    "col1.rename(index={'':'Unclassified'},inplace=True)\n",
    "\n",
    "print(col1.sum(axis=0))\n",
    "# col1.to_csv('test.csv')\n",
    "# col1.drop('Unclassified_sp', inplace=True)\n",
    "# Percent abundance operation.\n",
    "pct = col1.apply(lambda x: x / x.sum(), axis=0)\n",
    "display(pct)\n",
    "pct.to_csv(\"pipelines/bmock12/wgsa2/fullpct_genus.csv\", header=[\"Count\"], index_label=\"Genus\")\n",
    "\n",
    "# Drop features with less than x percent abundance.\n",
    "filtered_pct = pct.where(pct >= 0.001).dropna()\n",
    "\n",
    "# Add other category to account for dropped samples.\n",
    "filtered_pct.loc['Rare Taxa']= 1.0 - filtered_pct.sum(numeric_only=True, axis=0)\n",
    "display(pct)\n",
    "# pct.to_csv(\"pipelines/bmock12/wgsa2/0-001pct.csv\")\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.style.use('ggplot') \n",
    "filtered_pct.T.plot.bar(stacked=True, figsize=(10, 10), ylabel=\"Fraction\", xlabel=\"Sample\", title=\"Alignment Genus\").legend(loc='center left', bbox_to_anchor=(1.0, 0.5), title=\"Genus\")\n",
    "indices = pct.index\n",
    "cleaned_indices = [i.split(\"_\")[0] for i in indices]\n",
    "cleaned_indices = [i.replace(\"[\" , \"\") for i in cleaned_indices]\n",
    "cleaned_indices = [i.replace(\"]\" , \"\") for i in cleaned_indices]\n",
    "\n",
    "pct.index = cleaned_indices\n",
    "pct = pct.groupby(pct.index).sum()\n",
    "\n",
    "pct.to_csv(\"pipelines/bmock12/wgsa2/cleaned_pct.csv\")\n",
    "# Sort the values by the first sample in ascending order.\n",
    "pct.T\n",
    "pct.sort_values(axis=0, ascending=False, by=pct.columns[0], inplace=True)\n",
    "# Plot with seaborn.\n",
    "import plotly.express as px\n",
    "fig = px.bar(pct.T, x=pct.index, y=pct.columns, title=\"Alignment Species\", labels={'index': 'Sample', 'value': 'Fraction', \"variable\": \"Species\"})\n",
    "fig.show()\n",
    "# Sanity check to make sure my operations are correct.\n",
    "\n",
    "test_df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=['a', 'b', 'c'])\n",
    "\n",
    "pct_test = test_df.apply(lambda x: x / x.sum(), axis=0)\n",
    "display(pct_test)\n",
    "\n",
    "pct_test = pct_test.where(pct_test >= 0.50).dropna()\n",
    "display(pct_test)\n",
    "\n",
    "pct_test.loc['Column_Total']= 1.0 - pct_test.sum(numeric_only=True, axis=0)\n",
    "display(pct_test)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccb8790ce05d03335183e4531caa33d67ddc8515af0e7751497f278f4c676c90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
