{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 2023,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n",
            "plt.rcParams.update({'figure.max_open_warning': 0})\n",
            "\n",
            "from matplotlib.backends.backend_pdf import PdfPages\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.metrics import mean_squared_error\n",
            "from scipy.special import rel_entr\n",
            "import os\n",
            "# from python_src.compositions import replace_zero_aitchison\n",
            "# from python_src.compositions import replace_zeroes\n",
            "# from python_src.compositions import constant_aitchison\n",
            "# from python_src.compositions import add_constant\n",
            "from python_src.compositions import multiplicative_aitchison\n",
            "from skbio.stats.composition import multiplicative_replacement\n",
            "from scipy.spatial.distance import braycurtis, euclidean\n",
            "from scipy.stats import pearsonr\n",
            "from dataclasses import dataclass\n",
            "from python_src.compositions import clr\n",
            "from typing import Tuple"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Global Variables"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2024,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Change this depending on your data.\n",
            "# taxonomic_rank = 'Species'\n",
            "base_path = \"pipelines/camisimGI/bio4\"\n",
            "rel_abund_file = \"s1_genus_relabund.csv\"\n",
            "program_name = \"Biobakery4\"\n",
            "sample_id = \"s1\"\n",
            "\n",
            "expected_input = \"pipelines/camisimGI/s1_expected.csv\"\n",
            "\n",
            "pdf_output = PdfPages(\"figures.pdf\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Utils"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2025,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Use this once scipy fixes the bug.\n",
            "# from skbio.stats.composition import clr\n",
            "# from scipy.spatial.distance import euclidean\n",
            "\n",
            "# def aitchinson_distance(x, y):\n",
            "#     return euclidean(clr(x), clr(y))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Colors For Seaborn and MatplotLib"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2026,
         "metadata": {},
         "outputs": [],
         "source": [
            "cb_palette = sns.color_palette(as_cmap=True)\n",
            "\n",
            "# cb_palette = [\n",
            "# \"#e31a1c\",\n",
            "# \"#1f78b4\",\n",
            "# \"#b2df8a\",\n",
            "# \"#a6cee3\",\n",
            "# \"#fb9a99\",\n",
            "# \"#33a02c\",\n",
            "# ]\n",
            "\n",
            "# print(cb_palette)\n",
            "\n",
            "color_palette = {\n",
            "    \"Expected\": cb_palette[0], \n",
            "    \"expected\": cb_palette[0], \n",
            "    \"woltka\": cb_palette[1], \n",
            "    \"wol\": cb_palette[1], \n",
            "    \"jams\": cb_palette[2], \n",
            "    \"wgsa\": cb_palette[3], \n",
            "    \"wgsa2\": cb_palette[3], \n",
            "    \"biobakery3\": cb_palette[4], \n",
            "    \"bio3\": cb_palette[4], \n",
            "    \"biobakery4\": cb_palette[5], \n",
            "    \"bio4\": cb_palette[5]\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# One Sample, One Expected"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2027,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Generate the expected result from the tsv file. Returns a dataframe.\n",
            "def generate_expected(input_path: str, plot: bool = False, rank : str = \"Genus\") -> pd.DataFrame:\n",
            "    expected = pd.read_csv(input_path, sep=',', index_col=0, names=['Organism', 'Counts', 'TAX_ID'], header=0)\n",
            "    expected = expected[['Counts']].astype(int)\n",
            "\n",
            "    # Calculate expected relative abundance. If it's already in RA, this won't change anything.\n",
            "    expected['RA'] = expected['Counts'] / expected['Counts'].sum()\n",
            "\n",
            "    if rank == \"Species\":\n",
            "        expected.sort_values(by=['RA'], ascending=False, inplace=True)\n",
            "        return expected\n",
            "\n",
            "    # Let's split the organism index into two columns to find the genera.\n",
            "    orgs = expected.index.to_list()\n",
            "    genus = [org.strip().split(' ')[0] for org in orgs]\n",
            "    genus = [x.replace('M.', 'Micromonospora') for x in genus]\n",
            "\n",
            "    # Apparently, propionibacterium have been renamed to cutibacterium.\n",
            "    genus = [x.replace('Propionibact.', 'Cutibacterium') for x in genus]\n",
            "\n",
            "    # Add the columns to the dataframe.\n",
            "    expected['Genus'] = genus\n",
            "    # display(expected.head(12))\n",
            "\n",
            "    # Group by genus and sum the counts for overlapping genera.\n",
            "    exp_genus = expected.groupby('Genus').sum()\n",
            "    exp_genus.sort_values('RA', ascending=False, inplace=True)\n",
            "\n",
            "    if plot:\n",
            "        exp_genus.plot.bar(y='RA', figsize=(8, 5), legend=False, title='Expected Relative Abundance')\n",
            "    \n",
            "    return exp_genus\n",
            "\n",
            "# Use generate_expected to generate the expected result for the bmock12 data.\n",
            "# exp_genus = generate_expected('pipelines/bmock12/s1_expected_species.csv', False, \"Species\")\n",
            "# exp_genus[\"RA\"].to_csv('pipelines/bmock12/s1_expected_species.csv', index_label=\"Species\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2028,
         "metadata": {},
         "outputs": [],
         "source": [
            "# For camisim, we can just read the csv in directly.\n",
            "# exp_genus = pd.read_csv(expected_input, index_col=0, names=['Genus', 'RA'], header=0)\n",
            "# exp_genus = exp_genus.where(exp_genus['RA'] > 0.001).dropna()\n",
            "\n",
            "# (exp_genus.where(exp_genus['RA'] > 0.001).dropna()).to_csv('pipelines/camisimGI/s2_genus_pretty.csv', index_label=\"Genus\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2029,
         "metadata": {},
         "outputs": [],
         "source": [
            "def generate_experimental_df(input_path: str, index_name: str) -> pd.DataFrame:\n",
            "    # Now, load in the experimental values.\n",
            "    r_genus = pd.read_csv(input_path, index_col=0, names=[index_name, \"RA\", \"TAX_ID\"], header=0)\n",
            "    # display(r_genus.head(12))\n",
            "    r_genus = r_genus.astype({'RA': 'float64', 'TAX_ID': 'int64'})\n",
            "\n",
            "    return r_genus\n",
            "\n",
            "# Instead, let's concat the two dataframes into long format and add a column from where it originated.\n",
            "def long_format(df1, df2):\n",
            "    merged = pd.concat([df1, df2], axis=0)\n",
            "\n",
            "    # !!! This is slick\n",
            "    merged['Source'] = ['Expected'] * len(df1) + ['Observed'] * len(df2)\n",
            "\n",
            "    return merged\n",
            "\n",
            "# result_genus = generate_experimental_df(os.path.join(base_path, rel_abund_file), taxonomic_rank)\n",
            "# display(result_genus.head(12))\n",
            "# merged_lf = long_format(exp_genus, result_genus)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Plotting Tools"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2030,
         "metadata": {},
         "outputs": [],
         "source": [
            "def linear_regression(df: pd.DataFrame, exp_df: pd.DataFrame, plot: bool = False, save_path: str = None) -> pd.DataFrame:\n",
            "    # Merge on the genus key for easy plotting. The expected results are on the left, the observed on the right.\n",
            "    # linear_df = exp_genus.merge(df, left_index=True, right_index=True)\n",
            "\n",
            "    # try join because the left merge will drop the genera that are not in the observerd results, but we want to show that the experimental missed it.\n",
            "    linear_df = exp_df.join(df, how='left', lsuffix='_x', rsuffix='_y')\n",
            "    linear_df.fillna(0, inplace=True)\n",
            "\n",
            "    # Linear regression with scikit.\n",
            "    X = linear_df['RA_x'].values.reshape(-1, 1)\n",
            "    Y = linear_df['RA_y'].values.reshape(-1, 1)\n",
            "    reg = LinearRegression().fit(X, Y)\n",
            "    y_pred = reg.predict(X)\n",
            "\n",
            "    # Scatter plot of RA_x vs. RA_y.\n",
            "    if plot:\n",
            "        fig = plt.figure(figsize=(10, 8))\n",
            "        plt.scatter(linear_df['RA_x'], linear_df['RA_y'], color='black')\n",
            "\n",
            "        # Calculate mean absolute error.\n",
            "        mae = np.mean(np.abs(linear_df['RA_x'] - linear_df['RA_y']))\n",
            "\n",
            "        # Regression line.\n",
            "        plt.plot(X, y_pred, color='red', linewidth=2)\n",
            "        # Labels.\n",
            "        plt.xlabel('Expected Relative Abundance')\n",
            "        plt.ylabel('Observed Relative Abundance')\n",
            "        plt.title(f'Expected vs. Observed Relative Abundance for {program_name} {taxonomic_rank}')\n",
            "\n",
            "        # Add r^2 value.\n",
            "        plt.text(0.1, 0.9, f'r^2 = {reg.score(X,Y):.4f}', transform=plt.gca().transAxes)\n",
            "        # Add MAE.\n",
            "        plt.text(0.1, 0.85, f'MAE = {mae:.4f}', transform=plt.gca().transAxes)\n",
            "\n",
            "        # Add line y = x.\n",
            "        plt.plot([0, 1], [0, 1], color='blue', linewidth=2, linestyle='--')\n",
            "\n",
            "        if save_path is not None:\n",
            "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
            "\n",
            "        # plt.show()\n",
            "\n",
            "    return linear_df\n",
            "    \n",
            "# linear_regression(result_genus, exp_genus, plot=True, save_path=os.path.join(base_path, f\"{sample_id}_bivariate_{taxonomic_rank}.png\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2031,
         "metadata": {},
         "outputs": [],
         "source": [
            "def fix_x_labels(ax, df, rank):\n",
            "    xticks = ax.get_xticklabels()\n",
            "    # print(xticks)\n",
            "    new_labels = []\n",
            "    for x in xticks:\n",
            "        res = df.loc[int(x.get_text()), rank]\n",
            "        # Get only the first row from the series.\n",
            "        # This is necessary because if it is unique, it will return a string, but if it is not unique, it will return a series.\n",
            "        if isinstance(res, pd.Series):\n",
            "            res = res.iloc[0]\n",
            "        new_labels.append(res)\n",
            "\n",
            "    return new_labels"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2032,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Bar plot of RA_x vs. RA_y side by side.\n",
            "# sns.set_style(\"whitegrid\")\n",
            "def bar_plot(df: pd.DataFrame, plot: bool = False, save_path: str = None, program: str = program_name, title: str =f'INSERT TITLE', hue_category: str ='Source', taxonomic_rank: str = None, threshold: float = 5e-5):\n",
            "    # df.to_csv(\"debug.csv\", index=True)\n",
            "    subset = pd.DataFrame()\n",
            "\n",
            "    # Used to subset by taxonomic rank, but now TAX_ID?\n",
            "    # Need to test further.\n",
            "    for x, y in df.groupby(\"TAX_ID\"):\n",
            "        if y[\"Source\"].values[0] == \"Expected\":\n",
            "            subset = pd.concat([y, subset], axis=0)\n",
            "\n",
            "    # display(subset.head())\n",
            "    subset = subset.where(subset['RA'] > threshold).dropna()\n",
            "    # subset.to_csv(\"subset.csv\", index=True)\n",
            "\n",
            "    if plot:\n",
            "        # Plot a category bar chart with the colors based on the source.\n",
            "        fig = plt.figure(figsize=(10, 8))\n",
            "        ax = sns.barplot(x=subset.index, y='RA', hue=hue_category, data=subset, errorbar=None, palette=color_palette)\n",
            "        ax.semilogy()\n",
            "\n",
            "        ax.bar_label(ax.containers[0], fmt='%.2e', label_type='center')\n",
            "        # ax.bar_label(ax.containers[1], fmt='%.2e', label_type='edge')\n",
            "\n",
            "        # Change the x axis labels from the index to the taxonomic rank.\n",
            "        ax.set_xticklabels(fix_x_labels(ax=ax, df=subset, rank=taxonomic_rank), rotation=45, horizontalalignment='right')\n",
            "\n",
            "        # Later, we can fix the y labels.\n",
            "        # fix_y_labels(ax)\n",
            "\n",
            "        ax.set_title(title)\n",
            "        ax.set_xlabel(taxonomic_rank)\n",
            "        ax.set_ylabel('Relative Abundance')\n",
            "\n",
            "        if save_path is not None:\n",
            "            pdf_output.savefig(fig, dpi=300, bbox_inches='tight')\n",
            "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
            "            plt.close()\n",
            "\n",
            "        plt.show()\n",
            "\n",
            "# bar_plot(merged_lf, plot=True, save_path=os.path.join(base_path, f\"{sample_id}_bars_{taxonomic_rank}.png\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Multisample\n",
            "## Utilities"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2033,
         "metadata": {},
         "outputs": [],
         "source": [
            "# We will now aggregate the differences by pipeline. \n",
            "# To do this, we will start at the root and walk down, looking for \"relabund\" files and \"expected\" files.\n",
            "\n",
            "# root_dir = \"pipelines/camisimGI/\"\n",
            "\n",
            "def get_all_expected(root_dir: str, rank=\"Genus\"):\n",
            "    combined_expected = pd.DataFrame()\n",
            "    for root, dirs, files in os.walk(root_dir):\n",
            "        for f in files:\n",
            "            # print(\"files: \", files)\n",
            "            if f\"expected_{rank.lower()}_annotated\" in f and f.endswith(\".csv\"):\n",
            "                # print(f)\n",
            "                df = pd.read_csv(os.path.join(root, f), index_col=0, names=[rank, 'RA', \"TAX_ID\"], header=0)\n",
            "                df[\"Source\"] = \"Expected\"\n",
            "\n",
            "                # Files are of s#_expected.csv, so we can split on the underscore and take the first part.\n",
            "                df[\"SampleID\"] = f.split(\"_\")[0]\n",
            "                combined_expected = pd.concat([combined_expected, df], axis=0)\n",
            "\n",
            "    # combined_expected.reset_index(inplace=True)\n",
            "    # combined_expected.rename({\"index\": rank}, axis=1, inplace=True)\n",
            "    # combined_expected = combined_expected.set_index(\"TAX_ID\")\n",
            "\n",
            "    return combined_expected"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2034,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_relabund_files(root_dir: str, rank=\"genus\"):\n",
            "    combined_df = pd.DataFrame()\n",
            "    for root, dirs, files in os.walk(root_dir):\n",
            "        for f in files:\n",
            "            if f\"{rank.lower()}_relabund_annotated\" in f and f.endswith(\".csv\"):\n",
            "                # print(root, f)\n",
            "                p = os.path.join(root, f)\n",
            "                exp = generate_experimental_df(p, rank)\n",
            "\n",
            "                # Add a column to the experimental dataframe with the pipeline name.\n",
            "                exp['Source'] = os.path.dirname(p).split('/')[-1]\n",
            "\n",
            "                # Add sampleID to the experimental dataframe.\n",
            "                exp['SampleID'] = os.path.basename(p).split('_')[0]\n",
            "                # display(exp.head(10))\n",
            "\n",
            "                # Add the experimental dataframe to the combined dataframe.\n",
            "                combined_df = pd.concat([combined_df, exp], axis=0)\n",
            "\n",
            "    # Ensure that the RA column is a float.\n",
            "    combined_df['RA'] = combined_df['RA'].astype(float)\n",
            "\n",
            "    return combined_df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2035,
         "metadata": {},
         "outputs": [],
         "source": [
            "def fully_combined(root_dir, rank) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    Gathers all expected and experimental dataframes and combines them into a single dataframe.\n",
            "    \"\"\"\n",
            "    if rank is None:\n",
            "        raise Exception(\"Rank is not defined.\")\n",
            "\n",
            "    combined_df = get_relabund_files(root_dir, rank=rank)\n",
            "\n",
            "    combined_expected = get_all_expected(root_dir, rank=rank)\n",
            "\n",
            "    # Merge the expected and experimental dataframes.\n",
            "    merged = pd.concat([combined_expected, combined_df], axis=0)\n",
            "    merged = merged.reset_index()\n",
            "    merged = merged.rename(columns={'index': rank})\n",
            "\n",
            "    # merged = merged.astype({'TAX_ID': 'int64'})\n",
            "    merged = merged.set_index(\"TAX_ID\")\n",
            "\n",
            "    # display(merged.head())\n",
            "    # merged.to_csv(\"combined.csv\", index=True, index_label=\"TAX_ID\")\n",
            "\n",
            "    return merged"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2036,
         "metadata": {},
         "outputs": [],
         "source": [
            "def fix_outer_join_df(df: pd.DataFrame, source: str, threshold: float = 0.001) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    Parameters:\n",
            "        df: The dataframe to fix.\n",
            "        source: The source of the dataframe.\n",
            "        threshold: The threshold to use for the relative abundance.\n",
            "    \n",
            "    Returns:\n",
            "        pd.Dataframe: The fixed dataframe.\n",
            "\n",
            "    This function will fill the missing RA_expected, RA_observed, and Source_observed columns with 0s and the source name. \\\\ \n",
            "    We then filter out the rows where the RA_expected is less than the threshold. \\\\\n",
            "    We are doing this to penalize the pipeline for adding taxa that are not in the expected.\n",
            "    \"\"\"\n",
            "    # print(\"the threshold is \", threshold)\n",
            "    df['RA_expected'].fillna(0, inplace=True)\n",
            "    df['RA_observed'].fillna(0, inplace=True)\n",
            "    df['Source_observed'].fillna(source, inplace=True)\n",
            "\n",
            "    # Now, filter any rows with 'RA_observed' less than threshold if the corresponding RA_expected value is 0.\n",
            "    df = df.loc[(df['RA_expected'] > 0) | (df['RA_observed'] > threshold)]\n",
            "\n",
            "    return df"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Renormalize"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2037,
         "metadata": {},
         "outputs": [],
         "source": [
            "def renormalize_df(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    Parameters:\n",
            "        df: The dataframe to renormalize.\n",
            "\n",
            "    Returns:\n",
            "        pd.DataFrame: The renormalized dataframe.\n",
            "\n",
            "    This function will renormalize the relative abundance. \\\\\n",
            "    Specify the column name to renormalize.\n",
            "    \"\"\"\n",
            "    # Renormalize the experimental dataframes.\n",
            "    df[column_name] = df[column_name] / df[column_name].sum()\n",
            "\n",
            "    return df\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Join functions for the bivariate plots"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2038,
         "metadata": {},
         "outputs": [],
         "source": [
            "def join_left(expected: pd.DataFrame, source_df: pd.DataFrame, source_name: str, sampleID: str) -> pd.DataFrame:\n",
            "    \"\"\" \n",
            "    Parameters:\n",
            "        expected: The expected dataframe.\n",
            "        source_df: The source/experimental dataframe.\n",
            "        source_name: The name of the source.\n",
            "        sampleID: The sampleID of the source (can be None).\n",
            "    Returns:\n",
            "        pd.DataFrame: The joined dataframe.\n",
            "\n",
            "    This function will join the expected dataframe to the source dataframe by left join. \\\\\n",
            "    Then, it will fill the missing observed values with 0s and the source name, since there can be no missing expected values. \\\\.\n",
            "\n",
            "    \"\"\"\n",
            "    exp_copy = expected.copy()\n",
            "    src_copy = source_df.copy()\n",
            "\n",
            "    merged = pd.merge(exp_copy, src_copy, on=\"TAX_ID\", how='left', suffixes=('_expected', '_observed'))\n",
            "    merged['RA_observed'].fillna(0, inplace=True)\n",
            "    merged['Source_observed'].fillna(source_name, inplace=True)\n",
            "    if sampleID is not None:\n",
            "        merged['SampleID'] = sampleID\n",
            "\n",
            "    return merged\n",
            "\n",
            "def join_outer(expected: pd.DataFrame, source_df: pd.DataFrame, source_name: str, threshold: float) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    This function will join the expected dataframe to the source dataframe by outer join. \\\\\n",
            "    Then it will call fix_outer_join_df to fix the missing values and filter out the rows with RA_expected less than the threshold.\n",
            "    See: :func:`fix_outer_join_df`\n",
            "\n",
            "    ### Parameters:\n",
            "        expected: The expected dataframe.\n",
            "        source_df: The source/experimental dataframe.\n",
            "        source: The name of the source.\n",
            "        sample: The sampleID of the source (can be None).\n",
            "        threshold: The threshold to use for the relative abundance.\n",
            "    ### Returns:\n",
            "        pd.DataFrame: The joined dataframe.\n",
            "    \"\"\"\n",
            "        \n",
            "    exp_copy = expected.copy()\n",
            "    src_copy = source_df.copy()\n",
            "\n",
            "    merged = pd.merge(exp_copy, src_copy, on=\"TAX_ID\", how='outer', suffixes=('_expected', '_observed'))\n",
            "    merged = fix_outer_join_df(merged, source_name, threshold=threshold)\n",
            "\n",
            "    # Renormalize the dataframe since we filtered out some rows.\n",
            "    merged = renormalize_df(merged, 'RA_observed')\n",
            "    merged = renormalize_df(merged, 'RA_expected')\n",
            "\n",
            "    return merged\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Multisample with Different Expected Values"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2039,
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_by_sample(root, output_dir, taxonomic_rank, hue_category='Source', threshold=5e-5): \n",
            "    full_df = fully_combined(root, rank=taxonomic_rank)\n",
            "    \n",
            "    experiment_name = os.path.basename(root)\n",
            "    # print(root, experiment_name)\n",
            "\n",
            "    for sample_id, df in full_df.groupby('SampleID'):\n",
            "        title = f\"Expected vs. Observed Relative Abundance for {sample_id} in Experiment {experiment_name} ({taxonomic_rank})\"\n",
            "        # display(df.head())\n",
            "        if output_dir is not None:\n",
            "            bar_plot(df, plot=True, save_path=os.path.join(output_dir, f\"{sample_id}_bars_{taxonomic_rank}_all.png\"), title=title, taxonomic_rank=taxonomic_rank, hue_category=hue_category, threshold=threshold)\n",
            "        else:\n",
            "            bar_plot(df, plot=True, save_path=None, title=title, taxonomic_rank=taxonomic_rank, hue_category=hue_category, threshold=threshold)\n",
            "\n",
            "# plot_by_sample(root_dir, hue_category='SampleID')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2040,
         "metadata": {},
         "outputs": [],
         "source": [
            "def non_clr_plot(input_df: pd.DataFrame, hue_category: str, colors: dict, title: str):\n",
            "    lin_df = input_df.copy()\n",
            "    # Drop the rows with 0s in the RA_expected.\n",
            "    lin_df = lin_df[lin_df['RA_expected'] > 0]\n",
            "\n",
            "    # lin_df.to_csv(\"lin_df.csv\", index=True)\n",
            "\n",
            "    ax_lin = sns.lmplot(x=\"RA_expected\", y=\"RA_observed\", hue=hue_category, col=hue_category, col_wrap=3, data=lin_df, fit_reg=False, height=7, aspect=1, ci=None, palette=colors)\n",
            "\n",
            "    # Add the R^2 value to the plot.\n",
            "    def annotate(data, **kws):\n",
            "        max_x = data['RA_expected'].max()\n",
            "        max_y = data['RA_observed'].max()\n",
            "        max_val = max(max_x, max_y)\n",
            "\n",
            "        x = data[\"RA_expected\"].values.reshape(-1, 1)\n",
            "        y = data[\"RA_observed\"].values.reshape(-1, 1)\n",
            "\n",
            "        reg, y_pred = linear_regression(y,x)\n",
            "        r2 = reg.score(y, x)\n",
            "\n",
            "        mae = np.mean(np.abs(y - x))\n",
            "\n",
            "        ax = plt.gca()\n",
            "\n",
            "        ax.text(.05, .8, 'r2={:.4f}'.format(r2),\n",
            "                transform=ax.transAxes)\n",
            "\n",
            "        # Get the data from the plot.\n",
            "        ax.plot([0, max_val], [0, max_val], color='black', linestyle='--')\n",
            "\n",
            "        # Make it log scale.\n",
            "\n",
            "    ax_lin.map_dataframe(annotate)\n",
            "\n",
            "    ax_lin.fig.suptitle(title, fontsize=16)\n",
            "    plt.close(ax_lin.fig)\n",
            "    pdf_output.savefig(ax_lin.figure, bbox_inches='tight', dpi=300)\n",
            "    \n",
            "    # Make this a log-log plot.\n",
            "    # ax.set(xscale=\"log\", yscale=\"log\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2041,
         "metadata": {},
         "outputs": [],
         "source": [
            "def linear_regression(X, Y):\n",
            "    reg = LinearRegression().fit(X, Y)\n",
            "    y_pred = reg.predict(X)\n",
            "\n",
            "    return reg, y_pred\n",
            "\n",
            "def get_min_and_max_values(df: pd.DataFrame) -> Tuple[float, float]:\n",
            "    # Get the max x and max y values.\n",
            "    max_x = df['RA_expected_clr'].max()\n",
            "    max_y = df['RA_observed_clr'].max()\n",
            "    max_val = max(max_x, max_y)\n",
            "\n",
            "    min_x = df['RA_expected_clr'].min()\n",
            "    min_y = df['RA_observed_clr'].min()\n",
            "    min_val = min(min_x, min_y)\n",
            "\n",
            "    return max_val, min_val\n",
            "\n",
            "def linear_plot_stats(df: pd.DataFrame, heading: str, pipeline_offset: float):\n",
            "    \"\"\" \n",
            "    This function will calculate the R^2, RMSE, MAE, BC, and Aitchison distance for the given dataframe.\n",
            "    \"\"\"\n",
            "    stats_list = [heading]\n",
            "\n",
            "    # The R^2, MAE, RMS, and BC are calculated on the non-transformed data.\n",
            "    x = df[\"RA_expected\"].values.reshape(-1, 1)\n",
            "    y = df[\"RA_observed\"].values.reshape(-1, 1)\n",
            "\n",
            "    # We should probably perturb the x and y the same way we do the Aitchison values. \n",
            "    # For now, we will calculate the linear regression on the original values.\n",
            "    reg, y_pred = linear_regression(y, x)\n",
            "\n",
            "    # Calculate R^2.\n",
            "    r2 = reg.score(y, x)\n",
            "\n",
            "    # Add r^2\n",
            "    plt.text(-0.1, pipeline_offset, f'r\\u00b2 = {r2:.4f} for {heading}', transform=plt.gca().transAxes)\n",
            "    stats_list.append(r2)\n",
            "\n",
            "    # Calculate MAE.\n",
            "    mae = np.mean(np.abs(y - x))\n",
            "    stats_list.append(mae)\n",
            "\n",
            "    # Add MAE\n",
            "    plt.text(0.3, pipeline_offset, f'MAE = {mae:.4f} for {heading}', transform=plt.gca().transAxes)\n",
            "\n",
            "    # Add the aitchison distance.\n",
            "    try: \n",
            "        a_d = euclidean(df['RA_expected_clr'].values, df['RA_observed_clr'].values)\n",
            "        plt.text(0.7, pipeline_offset, f'AD = {a_d:.4f} for {heading}', transform=plt.gca().transAxes)\n",
            "        stats_list.append(a_d)\n",
            "\n",
            "    except ValueError as e:\n",
            "        print(f\"ValueError: {e}\")\n",
            "        # If there is a zero in the data, we cannot calculate the aitchison distance.\n",
            "        plt.text(0.65, pipeline_offset, f'AD = N/A for {heading}', transform=plt.gca().transAxes)\n",
            "        stats_list.append(np.NaN)\n",
            "\n",
            "    # Add the bray-curtis distance.\n",
            "    try: \n",
            "        bc = 1 - braycurtis(df['RA_expected'].values, df['RA_observed'].values)\n",
            "        plt.text(1.1, pipeline_offset, f'1-BC = {bc:.4f} for {heading}', transform=plt.gca().transAxes)\n",
            "        stats_list.append(bc)\n",
            "    except ValueError:\n",
            "        plt.text(1.1, pipeline_offset, f'1-BC = N/A for {heading}', transform=plt.gca().transAxes)\n",
            "        stats_list.append(np.NaN)\n",
            "\n",
            "    # Add the RMSE distance.\n",
            "    rms = mean_squared_error(y, x, squared=False)\n",
            "    plt.text(1.5, pipeline_offset, f'RMSE = {rms:.4f} for {heading}', transform=plt.gca().transAxes)\n",
            "    stats_list.append(rms)\n",
            "\n",
            "    stats_df = (pd.DataFrame(stats_list, index=['Source/Pipeline', 'R^2', 'MAE', 'AD', '1-BC', 'RMSE']).T).set_index('Source/Pipeline')\n",
            "\n",
            "    return stats_df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2042,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "def linear_plot(input_df: pd.DataFrame, title, sample_id, hue_category=\"Source_observed\", save_path=None, inset=False, colors=color_palette, linear=False) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    Plot a linear regression of the expected vs. observed relative abundance. Also calculates the R^2 value, MAE, RMSE, and Aitchison distance.\n",
            "    Parameters:\n",
            "        input_df: A dataframe with the expected and observed relative abundance. The third column should be the source of the data.\n",
            "        title: The title of the plot.\n",
            "        sample_id: The sample ID of the plot.\n",
            "        hue_category: The category to use for the hue (default: \"Source_observed\").\n",
            "        save_path: The path to save the plot to (if None, the plot will not be saved).\n",
            "        inset: Whether or not to plot the inset.\n",
            "        linear: Whether add plots of the non-CLR data.\n",
            "    Returns:\n",
            "        A dataframe with the R^2, MAE, and Aitchison distance with pipeline and sampleID.\n",
            "    \"\"\"\n",
            "    stats_df = pd.DataFrame()\n",
            "\n",
            "    fig = plt.figure(figsize=(10, 10))\n",
            "\n",
            "    # We need to transform the data to clr space before we plot.\n",
            "    plot_df = pd.DataFrame()\n",
            "    for heading, dataframe in input_df.groupby(hue_category):\n",
            "        # The constant value should be one order of magnitude smaller than the smallest NONZERO in the dataframe.\n",
            "        minimum = dataframe['RA_expected']\n",
            "        minimum = minimum[minimum > 0]\n",
            "        minimum = minimum.min() / 10\n",
            "\n",
            "        append_df = pd.DataFrame({\n",
            "            \"RA_expected_clr\": clr(multiplicative_replacement(dataframe[\"RA_expected\"], minimum)), \n",
            "            \"RA_observed_clr\": clr(multiplicative_replacement(dataframe[\"RA_observed\"], minimum)), \n",
            "            \"Source_observed\": heading,\n",
            "            \"RA_expected\": dataframe[\"RA_expected\"],\n",
            "            \"RA_observed\": dataframe[\"RA_observed\"],\n",
            "            \"SampleID_observed\": dataframe[\"SampleID_observed\"]}\n",
            "        )\n",
            "\n",
            "        plot_df = pd.concat([plot_df, append_df], axis=0)\n",
            "\n",
            "    ax = sns.lmplot(x=\"RA_expected_clr\", y=\"RA_observed_clr\", hue=hue_category, col=hue_category, col_wrap=3, data=plot_df, fit_reg=False, height=7, aspect=1, ci=None, palette=colors)\n",
            "\n",
            "    # Plot the non-CLR data if linear is wanted.\n",
            "    if linear:\n",
            "        non_clr_plot(plot_df, hue_category, colors, title)\n",
            "    \n",
            "    pipeline_offset = -0.1\n",
            "    for heading, dataframe in plot_df.groupby(hue_category):\n",
            "        # Convert the stats list to a dataframe, transpose it for rows, then concat it to the stats_df.\n",
            "        stats_df = pd.concat([stats_df, linear_plot_stats(dataframe, heading, pipeline_offset)], axis=0)\n",
            "        pipeline_offset -= 0.05\n",
            "\n",
            "    # Add a table with the stats_df to the plot.\n",
            "    # plt.table(cellText=stats_df.values, colLabels=stats_df.columns, loc='bottom right', fontsize=14)\n",
            "\n",
            "    # Add title.\n",
            "    ax.fig.suptitle(title, fontsize=16)\n",
            "\n",
            "    # Plot a line from (min-0.1, min-0.1) to (max_x+0.1, max_y+0.1) on all facets.\n",
            "    max_val, min_val = get_min_and_max_values(plot_df)\n",
            "    for a in plt.gcf().axes:\n",
            "        a.plot([min_val - 0.01, max_val + 0.01], [min_val - 0.01, max_val + 0.01], ls=\"--\", c=\".3\")\n",
            "\n",
            "    # Add an inset for the x values between 0 and 0.05.\n",
            "    if inset:\n",
            "        pass\n",
            "        # left, bottom, width, height = [0.65, 0.15, 0.25, 0.25]\n",
            "        # ax2 = ax.fig.add_axes([left, bottom, width, height])\n",
            "        # ax2 = sns.scatterplot(x=\"RA_expected\", y=\"RA_observed\", hue=hue_category, data=input_df, ax=ax2, legend=False, palette=colors)\n",
            "        # ax2.set_xlim(-0.001, 0.02)\n",
            "        # ax2.set_ylim(-0.001, 0.02)\n",
            "        # ax2.set_title(\"Zoomed In\")\n",
            "\n",
            "    display(stats_df)\n",
            "\n",
            "    if save_path is not None:\n",
            "        pdf_output.savefig(ax.figure, bbox_inches='tight', dpi=300)\n",
            "        plt.close(ax.figure)\n",
            "        \n",
            "\n",
            "    return stats_df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2043,
         "metadata": {},
         "outputs": [],
         "source": [
            "def linear_plot_log(input_df: pd.DataFrame, title, sample_id, hue_category=\"Source_observed\", save_path=None):\n",
            "    # We want to plot the x and y axis on a log scale.\n",
            "    fig = plt.figure(figsize=(20, 20))\n",
            "    ax = sns.lmplot(x=\"RA_expected\", y=\"RA_observed\", hue=hue_category, data=input_df, fit_reg=True, height=7, aspect=11/7, ci=None, truncate=True)\n",
            "    # ax.set(xscale=\"symlog\", yscale=\"symlog\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2044,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Since the sampleID and pipeline are changed depending on the hue color (for replicates), we need to change it here.\n",
            "def cleanup_bivariate_stats(df: pd.DataFrame, sampleID: str):\n",
            "    # We need to add a column equal to sampleID.\n",
            "    df['SampleID'] = sampleID\n",
            "\n",
            "    # Pop the old index.\n",
            "    df.reset_index(inplace=True)\n",
            "\n",
            "    # Set the index as the sampleID.\n",
            "    df.set_index(['SampleID'], inplace=True)\n",
            "\n",
            "    # We need to rename the \"index\" column to pipeline.\n",
            "    df.rename(columns={'index': 'Pipeline'}, inplace=True)\n",
            "\n",
            "    return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2045,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# Convert from Genus, RA, Source, SampleID to Genus RA_x, RA_y, Source, SampleID.\n",
            "def convert_to_bivariate(root_dir: str, save_path=None, inset=False, rank=None, threshold = 5e-5) -> pd.DataFrame:\n",
            "    if rank is None:\n",
            "        raise Exception(\"Rank cannot be None.\")\n",
            "\n",
            "    df = fully_combined(root_dir, rank=rank)\n",
            "\n",
            "    combined_stats = pd.DataFrame()\n",
            "    for sample, sample_df in df.groupby('SampleID'):\n",
            "        bivariate_df = pd.DataFrame()\n",
            "        # Get the expected dataframe.\n",
            "        expected = sample_df[sample_df['Source'] == 'Expected']\n",
            "\n",
            "        # Get the dirname of the root directory.\n",
            "        dirname = root_dir.split('/')[-1]\n",
            "        # print(dirname)\n",
            "\n",
            "        # Get the experimental dataframe.\n",
            "        experimental = sample_df[(sample_df['Source'] != 'Expected') & (sample_df['Source'] != dirname)]\n",
            "        # display(expected)\n",
            "        # display(experimental)\n",
            "\n",
            "        # We want to join outer on the expected dataframe after grouping by source. This will show the missing values from the expected.\n",
            "        for source, source_df in experimental.groupby('Source'):\n",
            "            # Merge the expected and experimental dataframes.\n",
            "\n",
            "            merged = join_left(expected, source_df, source_name=source, sampleID=sample)\n",
            "            # merged = join_outer(expected, source_df, source_name=source, threshold=threshold)\n",
            "\n",
            "            bivariate_df = pd.concat([bivariate_df, merged], axis=0)\n",
            "\n",
            "        # Add the merged dataframe to the bivariate dataframe.\n",
            "        # bivariate_df.to_csv('bmock12.csv', header=True)\n",
            "\n",
            "        title = f\"Bivariate Linear Regression for Sample {sample} in Experiment {dirname} ({rank})\"\n",
            "\n",
            "        # bivariate_df = bivariate_df.sort_values(by='RA_expected', ascending=False).head(30)\n",
            "        if save_path is not None:\n",
            "            stats_df = linear_plot(bivariate_df, title, sample, hue_category=\"Source_observed\", save_path=os.path.join(root_dir, f\"{sample}_linear_{rank}_all.png\"), inset=inset, linear=True)\n",
            "            stats_df = cleanup_bivariate_stats(stats_df, sample)\n",
            "\n",
            "            combined_stats = pd.concat([combined_stats, stats_df], axis=0)\n",
            "        else:\n",
            "            stats_df = linear_plot(bivariate_df, title, sample, hue_category=\"Source_observed\", save_path=None, linear=True)\n",
            "            stats_df = cleanup_bivariate_stats(stats_df, sample)\n",
            "\n",
            "            combined_stats = pd.concat([combined_stats, stats_df], axis=0)\n",
            "\n",
            "    return combined_stats\n",
            "# bivariate_df = convert_to_bivariate(fully_combined())"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Multiple Samples (Replicates) with One Expected"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2046,
         "metadata": {},
         "outputs": [],
         "source": [
            "# This function is used for multiple samples from the same pipeline against the same expected.\n",
            "def plot_many_versus_expected(root_dir, output_dir, in_df, rank, threshold):\n",
            "    expected = in_df[in_df['Source'] == 'Expected']\n",
            "    experimental = in_df[in_df['Source'] != 'Expected']\n",
            "\n",
            "    dirname = root_dir.split('/')[-1]\n",
            "    for pipeline, df in experimental.groupby('Source'):\n",
            "        # print(pipeline)\n",
            "        if pipeline == 'Expected':\n",
            "            raise Exception(\"Pipeline should not be Expected.\")\n",
            "        \n",
            "        if pipeline != dirname:\n",
            "            fig = plt.figure(figsize=(15, 12))\n",
            "\n",
            "            df = df.where(df['RA'] > threshold).dropna()\n",
            "\n",
            "            # display(df.head())\n",
            "\n",
            "            # Add the expected dataframe to the combined dataframe.\n",
            "            merged = pd.concat([expected, df], axis=0)\n",
            "\n",
            "            # Sample names change, so we can just use the same set of colors rather than having to change them.\n",
            "            ax = sns.barplot(x=merged.index, y='RA', hue=\"SampleID\", data=merged, errorbar=None, log=True, palette=cb_palette)\n",
            "            ticks = [0.001, 0.01, 0.10]\n",
            "            ax.set_yticks(ticks)\n",
            "            ax.set_yticklabels(ticks)\n",
            "            # ax.bar_label(ax.containers[0], fmt='%.2e', label_type='center')\n",
            "            # ax.bar_label(ax.containers[1], fmt='%.2e', label_type='edge')\n",
            "\n",
            "            ax.set_xticklabels(fix_x_labels(ax=ax, df=merged, rank=rank), rotation=45, horizontalalignment='right')\n",
            "            # ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
            "\n",
            "            title = f\"Expected vs. Observed Relative Abundance for {rank} using {pipeline} in Experiment {dirname}\"\n",
            "            ax.set_title(title)\n",
            "            ax.set_xlabel(rank)\n",
            "            ax.set_ylabel('Relative Abundance')\n",
            "\n",
            "            pdf_output.savefig(fig, bbox_inches='tight', dpi=300)\n",
            "            plt.close(fig)\n",
            "            # plt.savefig(os.path.join(output_dir, f\"{pipeline}\", f\"{pipeline}_bars.png\"), dpi=300, bbox_inches='tight')\n",
            "        else:\n",
            "            continue\n",
            "\n",
            "# plot_many_versus_expected(root_dir, fully_combined(), \"genus\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2047,
         "metadata": {},
         "outputs": [],
         "source": [
            "# This function will plot the expected vs. observed for each sample in each pipeline.\n",
            "# There is only one expected value for each sample since they are replicates.\n",
            "# This will be a bivariate plot.\n",
            "def plot_many_versus_expected_bivariate(root_dir, observed_df, expected_df, rank, inset, threshold) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    This function will plot the expected vs. observed for each sample in each pipeline. \n",
            "    There is only one expected value for each sample since they are replicates. \n",
            "    This will be a bivariate plot that will include MAE, r^2 and Aitchison distance.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    root_dir : str\n",
            "        The root directory of the pipeline.\n",
            "    observed_df : pd.DataFrame\n",
            "        The observed dataframe.\n",
            "    expected_df : pd.DataFrame\n",
            "        The expected dataframe.\n",
            "    rank : str\n",
            "        The taxonomic rank.\n",
            "    inset : bool\n",
            "        Whether or not to include an inset plot.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    pd.DataFrame\n",
            "        A dataframe containing the statistics for each sample.\n",
            "    \"\"\"\n",
            "    # First, we need to make a df of observed vs. expected for each sample.\n",
            "    combined_stats = pd.DataFrame()\n",
            "    for pipeline, pipeline_df in observed_df.groupby(\"Source\"):\n",
            "            # Plotting expected vs expected is useless.\n",
            "            if pipeline == \"tourlousse\" or pipeline == \"Expected\":\n",
            "                continue\n",
            "\n",
            "            # We are going to merge outer so that we can see which organisms are missing from the expected or are not supposed to be there. \n",
            "            merged = join_left(expected_df, pipeline_df, source_name=pipeline, sampleID=None)\n",
            "            # merged = join_outer(expected_df, pipeline_df, source_name=pipeline, threshold=threshold)\n",
            "\n",
            "            # merged.to_csv(\"bivariate_debug.csv\", mode='a')\n",
            "\n",
            "            save_path = os.path.join(root_dir, pipeline, f\"{pipeline}_bivariate_{rank}_all_samples.png\")\n",
            "            # merged.to_csv(os.path.join(root_dir, pipeline, f\"{pipeline}_bivariate_{rank}_all_samples.csv\"))\n",
            "\n",
            "            exp_name = os.path.basename(root_dir)\n",
            "\n",
            "            # Add amos to the mixed or hilo samples since they are nested.\n",
            "            if exp_name == \"mixed\" or exp_name == \"hilo\":\n",
            "                exp_name = \"Amos \" + exp_name\n",
            "\n",
            "            pipeline_stats = linear_plot(merged, f\"Expected vs. Observed Relative Abundance for {rank} using {pipeline} in Experiment {exp_name}\", pipeline, hue_category=\"SampleID_observed\", save_path=save_path, inset=inset, colors=cb_palette)\n",
            "\n",
            "            # Add pipeline column to the stats dataframe equal to the pipeline name.\n",
            "            pipeline_stats['Pipeline'] = pipeline\n",
            "\n",
            "            # Add the pipeline stats to the combined stats dataframe.\n",
            "            combined_stats = pd.concat([combined_stats, pipeline_stats], axis=0)\n",
            "\n",
            "    return combined_stats\n",
            "\n",
            "# plot_many_versus_expected_bivariate(get_relabund_files(root_dir), get_all_expected(root_dir, \"genus\"), \"genus\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Run the code here: MAIN."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2048,
         "metadata": {},
         "outputs": [],
         "source": [
            "# We can initialize the dataclasses to hold the parameters for each pipeline.\n",
            "@dataclass\n",
            "class Pipeline:\n",
            "    root: str\n",
            "    inset: bool\n",
            "\n",
            "    def __init__(self, root: str, inset: bool):\n",
            "        self.root = root\n",
            "        self.inset = inset\n",
            "\n",
            "bmock12 = Pipeline(\"pipelines/bmock12\", False)\n",
            "camisim = Pipeline(\"pipelines/camisimGI\", True)\n",
            "tourlousse = Pipeline(\"pipelines/tourlousse\", False)\n",
            "amos_hilo = Pipeline(\"pipelines/amos/hilo\", False)\n",
            "amos_mixed = Pipeline(\"pipelines/amos/mixed\", False)\n",
            "\n",
            "# No ending slash for these directories.\n",
            "root_dirs_one_to_one = [bmock12, camisim]\n",
            "# root_dirs_one_to_one = [bmock12]\n",
            "root_dirs_one_to_many = [tourlousse, amos_hilo, amos_mixed]\n",
            "# root_dirs_one_to_many = [amos_mixed]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2049,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Experiment:  pipelines/bmock12\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>R^2</th>\n",
                     "      <th>MAE</th>\n",
                     "      <th>AD</th>\n",
                     "      <th>1-BC</th>\n",
                     "      <th>RMSE</th>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>Source/Pipeline</th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>biobakery3</th>\n",
                     "      <td>0.010908</td>\n",
                     "      <td>0.175237</td>\n",
                     "      <td>11.944055</td>\n",
                     "      <td>0.299054</td>\n",
                     "      <td>0.252579</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>biobakery4</th>\n",
                     "      <td>0.012698</td>\n",
                     "      <td>0.177206</td>\n",
                     "      <td>8.380302</td>\n",
                     "      <td>0.291177</td>\n",
                     "      <td>0.257302</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>jams</th>\n",
                     "      <td>0.995686</td>\n",
                     "      <td>0.006514</td>\n",
                     "      <td>2.155385</td>\n",
                     "      <td>0.973554</td>\n",
                     "      <td>0.008581</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>wgsa2</th>\n",
                     "      <td>0.870142</td>\n",
                     "      <td>0.032633</td>\n",
                     "      <td>5.517696</td>\n",
                     "      <td>0.849873</td>\n",
                     "      <td>0.053012</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>woltka</th>\n",
                     "      <td>0.676564</td>\n",
                     "      <td>0.13778</td>\n",
                     "      <td>4.379758</td>\n",
                     "      <td>0.436803</td>\n",
                     "      <td>0.210836</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                      R^2       MAE         AD      1-BC      RMSE\n",
                     "Source/Pipeline                                                   \n",
                     "biobakery3       0.010908  0.175237  11.944055  0.299054  0.252579\n",
                     "biobakery4       0.012698  0.177206   8.380302  0.291177  0.257302\n",
                     "jams             0.995686  0.006514   2.155385  0.973554  0.008581\n",
                     "wgsa2            0.870142  0.032633   5.517696  0.849873  0.053012\n",
                     "woltka           0.676564   0.13778   4.379758  0.436803  0.210836"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>R^2</th>\n",
                     "      <th>MAE</th>\n",
                     "      <th>AD</th>\n",
                     "      <th>1-BC</th>\n",
                     "      <th>RMSE</th>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>Source/Pipeline</th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>biobakery3</th>\n",
                     "      <td>0.222242</td>\n",
                     "      <td>0.102588</td>\n",
                     "      <td>16.385557</td>\n",
                     "      <td>0.373171</td>\n",
                     "      <td>0.178928</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>biobakery4</th>\n",
                     "      <td>0.218245</td>\n",
                     "      <td>0.103464</td>\n",
                     "      <td>16.34328</td>\n",
                     "      <td>0.37094</td>\n",
                     "      <td>0.184137</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>jams</th>\n",
                     "      <td>0.075163</td>\n",
                     "      <td>0.099524</td>\n",
                     "      <td>21.858902</td>\n",
                     "      <td>0.196317</td>\n",
                     "      <td>0.133769</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>wgsa2</th>\n",
                     "      <td>0.100655</td>\n",
                     "      <td>0.088595</td>\n",
                     "      <td>22.825714</td>\n",
                     "      <td>0.155316</td>\n",
                     "      <td>0.108971</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>woltka</th>\n",
                     "      <td>0.119375</td>\n",
                     "      <td>0.156364</td>\n",
                     "      <td>18.988335</td>\n",
                     "      <td>0.000048</td>\n",
                     "      <td>0.276109</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                      R^2       MAE         AD      1-BC      RMSE\n",
                     "Source/Pipeline                                                   \n",
                     "biobakery3       0.222242  0.102588  16.385557  0.373171  0.178928\n",
                     "biobakery4       0.218245  0.103464   16.34328   0.37094  0.184137\n",
                     "jams             0.075163  0.099524  21.858902  0.196317  0.133769\n",
                     "wgsa2            0.100655  0.088595  22.825714  0.155316  0.108971\n",
                     "woltka           0.119375  0.156364  18.988335  0.000048  0.276109"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "<Figure size 1000x1000 with 0 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "<Figure size 1000x1000 with 0 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "def main():\n",
            "    # This is the minimum RA abundance.\n",
            "    filtering_threshold = 0.001\n",
            "\n",
            "    def one_to_one():\n",
            "        for exp in root_dirs_one_to_one:\n",
            "            print(\"Experiment: \", exp.root)\n",
            "            plot_by_sample(root=exp.root, output_dir=exp.root, hue_category=\"Source\", taxonomic_rank=\"Genus\", threshold=filtering_threshold)\n",
            "            plot_by_sample(root=exp.root, output_dir=exp.root, hue_category=\"Source\", taxonomic_rank=\"Species\", threshold=filtering_threshold)\n",
            "            final_stats = convert_to_bivariate(exp.root, save_path=exp.root, inset=exp.inset, rank=\"Genus\", threshold=filtering_threshold)\n",
            "            final_stats = convert_to_bivariate(exp.root, save_path=exp.root, inset=exp.inset, rank=\"Species\", threshold=filtering_threshold)\n",
            "            final_stats.to_csv(os.path.join(exp.root, \"all_stats_replicates.csv\"), index_label=\"SampleID\")\n",
            "\n",
            "    def many_to_one():\n",
            "        for exp in root_dirs_one_to_many:\n",
            "            print(\"Experiment: \", exp.root)\n",
            "            plot_many_versus_expected(exp.root, exp.root, fully_combined(exp.root, rank=\"genus\"), \"genus\", filtering_threshold)\n",
            "            plot_many_versus_expected(exp.root, exp.root, fully_combined(exp.root, rank=\"species\"), \"species\", filtering_threshold)\n",
            "            final_stats = plot_many_versus_expected_bivariate(exp.root, fully_combined(exp.root, rank=\"genus\"), get_all_expected(exp.root, \"genus\"), \"genus\", inset=exp.inset, threshold=filtering_threshold)\n",
            "            final_stats = plot_many_versus_expected_bivariate(exp.root, fully_combined(exp.root, rank=\"species\"), get_all_expected(exp.root, \"species\"), \"species\", inset=exp.inset, threshold=filtering_threshold)\n",
            "            final_stats.to_csv(os.path.join(exp.root, \"all_stats_replicates.csv\"), index_label=\"SampleID\")\n",
            "\n",
            "    one_to_one()\n",
            "    many_to_one()\n",
            "    pdf_output.close()\n",
            "    \n",
            "main()\n",
            "\n",
            "# fc = fully_combined(\"pipelines/bmock12/\")\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.6"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
