{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.special import rel_entr\n",
    "import os\n",
    "# from python_src.compositions import replace_zero_aitchison\n",
    "# from python_src.compositions import replace_zeroes\n",
    "# from python_src.compositions import constant_aitchison\n",
    "# from python_src.compositions import add_constant\n",
    "from python_src.compositions import multiplicative_aitchison\n",
    "from skbio.stats.composition import multiplicative_replacement\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from dataclasses import dataclass\n",
    "from python_src.compositions import clr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this depending on your data.\n",
    "# taxonomic_rank = 'Species'\n",
    "base_path = \"pipelines/camisimGI/bio4\"\n",
    "rel_abund_file = \"s1_genus_relabund.csv\"\n",
    "program_name = \"Biobakery4\"\n",
    "sample_id = \"s1\"\n",
    "\n",
    "expected_input = \"pipelines/camisimGI/s1_expected.csv\"\n",
    "\n",
    "pdf_output = PdfPages(\"figures.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this once scipy fixes the bug.\n",
    "# from skbio.stats.composition import clr\n",
    "# from scipy.spatial.distance import euclidean\n",
    "\n",
    "# def aitchinson_distance(x, y):\n",
    "#     return euclidean(clr(x), clr(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors For Seaborn and MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_palette = sns.color_palette(as_cmap=True)\n",
    "\n",
    "# cb_palette = [\n",
    "# \"#e31a1c\",\n",
    "# \"#1f78b4\",\n",
    "# \"#b2df8a\",\n",
    "# \"#a6cee3\",\n",
    "# \"#fb9a99\",\n",
    "# \"#33a02c\",\n",
    "# ]\n",
    "\n",
    "# print(cb_palette)\n",
    "\n",
    "color_palette = {\n",
    "    \"Expected\": cb_palette[0], \n",
    "    \"expected\": cb_palette[0], \n",
    "    \"woltka\": cb_palette[1], \n",
    "    \"wol\": cb_palette[1], \n",
    "    \"jams\": cb_palette[2], \n",
    "    \"wgsa\": cb_palette[3], \n",
    "    \"wgsa2\": cb_palette[3], \n",
    "    \"biobakery3\": cb_palette[4], \n",
    "    \"bio3\": cb_palette[4], \n",
    "    \"biobakery4\": cb_palette[5], \n",
    "    \"bio4\": cb_palette[5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Sample, One Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the expected result from the tsv file. Returns a dataframe.\n",
    "def generate_expected(input_path: str, plot: bool = False, rank : str = \"Genus\") -> pd.DataFrame:\n",
    "    expected = pd.read_csv(input_path, sep=',', index_col=0, names=['Organism', 'Counts', 'TAX_ID'], header=0)\n",
    "    expected = expected[['Counts']].astype(int)\n",
    "\n",
    "    # Calculate expected relative abundance. If it's already in RA, this won't change anything.\n",
    "    expected['RA'] = expected['Counts'] / expected['Counts'].sum()\n",
    "\n",
    "    if rank == \"Species\":\n",
    "        expected.sort_values(by=['RA'], ascending=False, inplace=True)\n",
    "        return expected\n",
    "\n",
    "    # Let's split the organism index into two columns to find the genera.\n",
    "    orgs = expected.index.to_list()\n",
    "    genus = [org.strip().split(' ')[0] for org in orgs]\n",
    "    genus = [x.replace('M.', 'Micromonospora') for x in genus]\n",
    "\n",
    "    # Apparently, propionibacterium have been renamed to cutibacterium.\n",
    "    genus = [x.replace('Propionibact.', 'Cutibacterium') for x in genus]\n",
    "\n",
    "    # Add the columns to the dataframe.\n",
    "    expected['Genus'] = genus\n",
    "    # display(expected.head(12))\n",
    "\n",
    "    # Group by genus and sum the counts for overlapping genera.\n",
    "    exp_genus = expected.groupby('Genus').sum()\n",
    "    exp_genus.sort_values('RA', ascending=False, inplace=True)\n",
    "\n",
    "    if plot:\n",
    "        exp_genus.plot.bar(y='RA', figsize=(8, 5), legend=False, title='Expected Relative Abundance')\n",
    "    \n",
    "    return exp_genus\n",
    "\n",
    "# Use generate_expected to generate the expected result for the bmock12 data.\n",
    "# exp_genus = generate_expected('pipelines/bmock12/s1_expected_species.csv', False, \"Species\")\n",
    "# exp_genus[\"RA\"].to_csv('pipelines/bmock12/s1_expected_species.csv', index_label=\"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For camisim, we can just read the csv in directly.\n",
    "# exp_genus = pd.read_csv(expected_input, index_col=0, names=['Genus', 'RA'], header=0)\n",
    "# exp_genus = exp_genus.where(exp_genus['RA'] > 0.001).dropna()\n",
    "\n",
    "# (exp_genus.where(exp_genus['RA'] > 0.001).dropna()).to_csv('pipelines/camisimGI/s2_genus_pretty.csv', index_label=\"Genus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experimental_df(input_path: str, index_name: str) -> pd.DataFrame:\n",
    "    # Now, load in the experimental values.\n",
    "    r_genus = pd.read_csv(input_path, index_col=0, names=[index_name, \"RA\", \"TAX_ID\"], header=0)\n",
    "    # display(r_genus.head(12))\n",
    "    r_genus = r_genus.astype({'RA': 'float64', 'TAX_ID': 'int64'})\n",
    "\n",
    "    return r_genus\n",
    "\n",
    "# Instead, let's concat the two dataframes into long format and add a column from where it originated.\n",
    "def long_format(df1, df2):\n",
    "    merged = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "    # !!! This is slick\n",
    "    merged['Source'] = ['Expected'] * len(df1) + ['Observed'] * len(df2)\n",
    "\n",
    "    return merged\n",
    "\n",
    "# result_genus = generate_experimental_df(os.path.join(base_path, rel_abund_file), taxonomic_rank)\n",
    "# display(result_genus.head(12))\n",
    "# merged_lf = long_format(exp_genus, result_genus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(df: pd.DataFrame, exp_df: pd.DataFrame, plot: bool = False, save_path: str = None) -> pd.DataFrame:\n",
    "    # Merge on the genus key for easy plotting. The expected results are on the left, the observed on the right.\n",
    "    # linear_df = exp_genus.merge(df, left_index=True, right_index=True)\n",
    "\n",
    "    # try join because the left merge will drop the genera that are not in the observerd results, but we want to show that the experimental missed it.\n",
    "    linear_df = exp_df.join(df, how='left', lsuffix='_x', rsuffix='_y')\n",
    "    linear_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Linear regression with scikit.\n",
    "    X = linear_df['RA_x'].values.reshape(-1, 1)\n",
    "    Y = linear_df['RA_y'].values.reshape(-1, 1)\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    y_pred = reg.predict(X)\n",
    "\n",
    "    # Scatter plot of RA_x vs. RA_y.\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(linear_df['RA_x'], linear_df['RA_y'], color='black')\n",
    "\n",
    "        # Calculate mean absolute error.\n",
    "        mae = np.mean(np.abs(linear_df['RA_x'] - linear_df['RA_y']))\n",
    "\n",
    "        # Regression line.\n",
    "        plt.plot(X, y_pred, color='red', linewidth=2)\n",
    "        # Labels.\n",
    "        plt.xlabel('Expected Relative Abundance')\n",
    "        plt.ylabel('Observed Relative Abundance')\n",
    "        plt.title(f'Expected vs. Observed Relative Abundance for {program_name} {taxonomic_rank}')\n",
    "\n",
    "        # Add r^2 value.\n",
    "        plt.text(0.1, 0.9, f'r^2 = {reg.score(X,Y):.4f}', transform=plt.gca().transAxes)\n",
    "        # Add MAE.\n",
    "        plt.text(0.1, 0.85, f'MAE = {mae:.4f}', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Add line y = x.\n",
    "        plt.plot([0, 1], [0, 1], color='blue', linewidth=2, linestyle='--')\n",
    "\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "    return linear_df\n",
    "    \n",
    "# linear_regression(result_genus, exp_genus, plot=True, save_path=os.path.join(base_path, f\"{sample_id}_bivariate_{taxonomic_rank}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_x_labels(ax, df, rank):\n",
    "    xticks = ax.get_xticklabels()\n",
    "    # print(xticks)\n",
    "    new_labels = []\n",
    "    for x in xticks:\n",
    "        res = df.loc[int(x.get_text()), rank]\n",
    "        # Get only the first row from the series.\n",
    "        # This is necessary because if it is unique, it will return a string, but if it is not unique, it will return a series.\n",
    "        if isinstance(res, pd.Series):\n",
    "            res = res.iloc[0]\n",
    "        new_labels.append(res)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of RA_x vs. RA_y side by side.\n",
    "# sns.set_style(\"whitegrid\")\n",
    "def bar_plot(df: pd.DataFrame, plot: bool = False, save_path: str = None, program=program_name, title=f'INSERT TITLE', hue_category='Source', taxonomic_rank = None):\n",
    "    # df.to_csv(\"debug.csv\", index=True)\n",
    "    subset = pd.DataFrame()\n",
    "\n",
    "    # Used to subset by taxonomic rank, but now TAX_ID?\n",
    "    # Need to test further.\n",
    "    for x, y in df.groupby(\"TAX_ID\"):\n",
    "        if y[\"Source\"].values[0] == \"Expected\":\n",
    "            subset = pd.concat([y, subset], axis=0)\n",
    "\n",
    "    # display(subset.head())\n",
    "    subset = subset.where(subset['RA'] > 5e-6).dropna()\n",
    "    # subset.to_csv(\"subset.csv\", index=True)\n",
    "\n",
    "    if plot:\n",
    "        # Plot a category bar chart with the colors based on the source.\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = sns.barplot(x=subset.index, y='RA', hue=hue_category, data=subset, errorbar=None, palette=color_palette)\n",
    "        ax.semilogy()\n",
    "\n",
    "        ax.bar_label(ax.containers[0], fmt='%.2e', label_type='center')\n",
    "        # ax.bar_label(ax.containers[1], fmt='%.2e', label_type='edge')\n",
    "\n",
    "        # Change the x axis labels from the index to the taxonomic rank.\n",
    "        ax.set_xticklabels(fix_x_labels(ax=ax, df=subset, rank=taxonomic_rank), rotation=45, horizontalalignment='right')\n",
    "\n",
    "        # Later, we can fix the y labels.\n",
    "        # fix_y_labels(ax)\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(taxonomic_rank)\n",
    "        ax.set_ylabel('Relative Abundance')\n",
    "\n",
    "        if save_path is not None:\n",
    "            pdf_output.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# bar_plot(merged_lf, plot=True, save_path=os.path.join(base_path, f\"{sample_id}_bars_{taxonomic_rank}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multisample\n",
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now aggregate the differences by pipeline. \n",
    "# To do this, we will start at the root and walk down, looking for \"relabund\" files and \"expected\" files.\n",
    "\n",
    "# root_dir = \"pipelines/camisimGI/\"\n",
    "\n",
    "def get_all_expected(root_dir: str, rank=\"Genus\"):\n",
    "    combined_expected = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            # print(\"files: \", files)\n",
    "            if f\"expected_{rank.lower()}_annotated\" in f and f.endswith(\".csv\"):\n",
    "                # print(f)\n",
    "                df = pd.read_csv(os.path.join(root, f), index_col=0, names=[rank, 'RA', \"TAX_ID\"], header=0)\n",
    "                df[\"Source\"] = \"Expected\"\n",
    "\n",
    "                # Files are of s#_expected.csv, so we can split on the underscore and take the first part.\n",
    "                df[\"SampleID\"] = f.split(\"_\")[0]\n",
    "                combined_expected = pd.concat([combined_expected, df], axis=0)\n",
    "\n",
    "    # combined_expected.reset_index(inplace=True)\n",
    "    # combined_expected.rename({\"index\": rank}, axis=1, inplace=True)\n",
    "    # combined_expected = combined_expected.set_index(\"TAX_ID\")\n",
    "\n",
    "    return combined_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relabund_files(root_dir: str, rank=\"genus\"):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if f\"{rank.lower()}_relabund_annotated\" in f and f.endswith(\".csv\"):\n",
    "                # print(root, f)\n",
    "                p = os.path.join(root, f)\n",
    "                exp = generate_experimental_df(p, rank)\n",
    "\n",
    "                # Add a column to the experimental dataframe with the pipeline name.\n",
    "                exp['Source'] = os.path.dirname(p).split('/')[-1]\n",
    "\n",
    "                # Add sampleID to the experimental dataframe.\n",
    "                exp['SampleID'] = os.path.basename(p).split('_')[0]\n",
    "                # display(exp.head(10))\n",
    "\n",
    "                # Add the experimental dataframe to the combined dataframe.\n",
    "                combined_df = pd.concat([combined_df, exp], axis=0)\n",
    "\n",
    "    # Ensure that the RA column is a float.\n",
    "    combined_df['RA'] = combined_df['RA'].astype(float)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_combined(root_dir, rank) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gathers all expected and experimental dataframes and combines them into a single dataframe.\n",
    "    \"\"\"\n",
    "    if rank is None:\n",
    "        raise Exception(\"Rank is not defined.\")\n",
    "\n",
    "    combined_df = get_relabund_files(root_dir, rank=rank)\n",
    "\n",
    "    combined_expected = get_all_expected(root_dir, rank=rank)\n",
    "\n",
    "    # Merge the expected and experimental dataframes.\n",
    "    merged = pd.concat([combined_expected, combined_df], axis=0)\n",
    "    merged = merged.reset_index()\n",
    "    merged = merged.rename(columns={'index': rank})\n",
    "\n",
    "    # merged = merged.astype({'TAX_ID': 'int64'})\n",
    "    merged = merged.set_index(\"TAX_ID\")\n",
    "\n",
    "    # display(merged.head())\n",
    "    # merged.to_csv(\"combined.csv\", index=True, index_label=\"TAX_ID\")\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_outer_join_df(df: pd.DataFrame, source: str, threshold: float = 0.001) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        df: The dataframe to fix.\n",
    "        source: The source of the dataframe.\n",
    "        threshold: The threshold to use for the relative abundance.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Dataframe: The fixed dataframe.\n",
    "\n",
    "    This function will fill the missing RA_expected, RA_observed, and Source_observed columns with 0s and the source name. \\\\ \n",
    "    We then filter out the rows where the RA_expected is less than the threshold. \\\\\n",
    "    We are doing this to penalize the pipeline for adding taxa that are not in the expected.\n",
    "    \"\"\"\n",
    "    df['RA_expected'].fillna(0, inplace=True)\n",
    "    df['RA_observed'].fillna(0, inplace=True)\n",
    "    df['Source_observed'].fillna(source, inplace=True)\n",
    "\n",
    "    # Now, filter any rows with 'RA_observed' less than 0.001.\n",
    "    df = df[df['RA_observed'] > threshold]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multisample with Different Expected Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_sample(root, output_dir, taxonomic_rank, hue_category='Source'): \n",
    "    full_df = fully_combined(root, rank=taxonomic_rank)\n",
    "    \n",
    "    experiment_name = os.path.basename(root)\n",
    "    print(root, experiment_name)\n",
    "\n",
    "    for sample_id, df in full_df.groupby('SampleID'):\n",
    "        title = f\"Expected vs. Observed Relative Abundance for {sample_id} in Experiment {experiment_name} ({taxonomic_rank})\"\n",
    "        # display(df.head())\n",
    "        if output_dir is not None:\n",
    "            bar_plot(df, plot=True, save_path=os.path.join(output_dir, f\"{sample_id}_bars_{taxonomic_rank}_all.png\"), title=title, taxonomic_rank=taxonomic_rank, hue_category=hue_category)\n",
    "        else:\n",
    "            bar_plot(df, plot=True, save_path=None, title=title, taxonomic_rank=taxonomic_rank, hue_category=hue_category)\n",
    "\n",
    "# plot_by_sample(root_dir, hue_category='SampleID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, Y):\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    y_pred = reg.predict(X)\n",
    "\n",
    "    return reg, y_pred\n",
    "\n",
    "def linear_plot(input_df: pd.DataFrame, title, sample_id, hue_category=\"Source_observed\", save_path=None, inset=False, colors=color_palette) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Plot a linear regression of the expected vs. observed relative abundance. Also calculates the R^2 value, MAE, and Aitchison distance.\n",
    "    Parameters:\n",
    "        input_df: A dataframe with the expected and observed relative abundance. The third column should be the source of the data.\n",
    "        title: The title of the plot.\n",
    "        sample_id: The sample ID of the plot.\n",
    "        hue_category: The category to use for the hue (default: \"Source_observed\").\n",
    "        save_path: The path to save the plot to (if None, the plot will not be saved).\n",
    "        inset: Whether or not to plot the inset.\n",
    "    Returns:\n",
    "        A dataframe with the R^2, MAE, and Aitchison distance with pipeline and sampleID.\n",
    "    \"\"\"\n",
    "    # input_df.to_csv(\"bivariate.csv\", mode='a', index=True)\n",
    "    stats_df = pd.DataFrame()\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = sns.lmplot(x=\"RA_expected\", y=\"RA_observed\", hue=hue_category, data=input_df, fit_reg=True, height=7, aspect=11/7, ci=None, palette=colors)\n",
    "\n",
    "    # Make linear regression for each pipeline (or sampleID for replicates).\n",
    "    pipeline_offset = -0.1\n",
    "    for heading, dataframe in input_df.groupby(hue_category):\n",
    "        # TODO: Perturb these values.\n",
    "        x = dataframe[\"RA_expected\"].values.reshape(-1, 1)\n",
    "        y = dataframe[\"RA_observed\"].values.reshape(-1, 1)\n",
    "\n",
    "        # We should probably perturb the x and y the same way we do the aitchison values. \n",
    "        # For now, we will calculate the linear regression on the original values.\n",
    "        reg, y_pred = linear_regression(x, y)\n",
    "\n",
    "        # Calculate R^2.\n",
    "        r2 = reg.score(x, y)\n",
    "\n",
    "        # Add r^2\n",
    "        plt.text(0.1, pipeline_offset, f'r\\u00b2 = {r2:.4f} for {heading}', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Calculate MAE.\n",
    "        mae = np.mean(np.abs(x - y))\n",
    "\n",
    "        # Add MAE\n",
    "        plt.text(0.4, pipeline_offset, f'MAE = {mae:.4f} for {heading}', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Add the aitchison distance.\n",
    "        try: \n",
    "            # a_d = replace_zero_aitchison(dataframe['RA_expected'].values, dataframe['RA_observed'].values)\n",
    "            # dataframe.to_csv(\"aitchison.csv\", mode='a', index=True)\n",
    "\n",
    "            # The constant value should be one order of magnitude smaller than the smallest value in the dataframe.\n",
    "            # minimum = dataframe['RA_expected'].min() / 10\n",
    "\n",
    "            a_d = multiplicative_aitchison(dataframe['RA_expected'].values, dataframe['RA_observed'].values)\n",
    "            plt.text(0.7, pipeline_offset, f'Aitchison = {a_d:.4f} for {heading}', transform=plt.gca().transAxes)\n",
    "\n",
    "            # Make a dataframe with sampleID as the index and the R^2, MAE, and Aitchison distance as the columns.\n",
    "            stats = {'R^2': r2, 'MAE': mae, 'Aitchison': a_d}\n",
    "            stats_df = pd.concat([stats_df, pd.DataFrame(stats, index=[heading])])\n",
    "\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"ValueError: {e}\")\n",
    "            # If there is a zero in the data, we cannot calculate the aitchison distance.\n",
    "            plt.text(0.7, pipeline_offset, f'Aitchison = N/A for {heading}', transform=plt.gca().transAxes)\n",
    "\n",
    "            # s = pd.Series({'SampleID': sample_id, 'Pipeline': heading, 'R^2': r2, 'MAE': mae, 'Aitchison': np.nan}) \n",
    "            # stats_df = pd.concat([stats_df, s], ignore_index=True)\n",
    "\n",
    "        \"\"\"\n",
    "        # Add the bray-curtis distance.\n",
    "        try: \n",
    "            a_d = 1 - braycurtis(dataframe['RA_expected'].values, dataframe['RA_observed'].values)\n",
    "            plt.text(0.7, pipeline_offset, f'1-BC = {a_d:.4f} for {heading}', transform=plt.gca().transAxes)\n",
    "        except ValueError:\n",
    "            plt.text(0.7, pipeline_offset, f'1-BC = N/A for {heading}', transform=plt.gca().transAxes)\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate relative entropy using scipy.special.rel_entr\n",
    "        # Not sure if this works since sometimes the observed is smaller than the expected.\n",
    "        # re = rel_entr(dataframe['RA_expected'], dataframe['RA_observed']).sum()\n",
    "        # print(re)\n",
    "        # Add relative entropy\n",
    "        # plt.text(0.7, pipeline_offset, f'Relative Entropy = {re:.4f} for {heading}', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Move the offset down. \n",
    "        pipeline_offset -= 0.05\n",
    "\n",
    "    # Add title.\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add y = x line.\n",
    "    ## Get the max x and max y values.\n",
    "    max_x = input_df['RA_expected'].max()\n",
    "    max_y = input_df['RA_observed'].max()\n",
    "    max_val = max(max_x, max_y)\n",
    "    \n",
    "    # Plot a line from (0, 0) to (max_x+0.1, max_y+0.1)\n",
    "    plt.plot([0, max_val + 0.01], [0, max_val + 0.01], ls=\"--\", c=\".3\")\n",
    "\n",
    "    # Add an inset for the x values between 0 and 0.05.\n",
    "    if inset:\n",
    "        left, bottom, width, height = [0.65, 0.15, 0.25, 0.25]\n",
    "        ax2 = ax.fig.add_axes([left, bottom, width, height])\n",
    "        ax2 = sns.scatterplot(x=\"RA_expected\", y=\"RA_observed\", hue=hue_category, data=input_df, ax=ax2, legend=False, palette=colors)\n",
    "        ax2.set_xlim(-0.001, 0.02)\n",
    "        ax2.set_ylim(-0.001, 0.02)\n",
    "        ax2.set_title(\"Zoomed In\")\n",
    "\n",
    "    if save_path is not None:\n",
    "        pdf_output.savefig(ax.figure, bbox_inches='tight', dpi=300)\n",
    "        plt.close(ax.figure)\n",
    "        \n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_plot_log(input_df: pd.DataFrame, title, sample_id, hue_category=\"Source_observed\", save_path=None):\n",
    "    # We want to plot the x and y axis on a log scale.\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax = sns.lmplot(x=\"RA_expected\", y=\"RA_observed\", hue=hue_category, data=input_df, fit_reg=True, height=7, aspect=11/7, ci=None, truncate=True)\n",
    "    # ax.set(xscale=\"symlog\", yscale=\"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the sampleID and pipeline are changed depending on the hue color (for replicates), we need to change it here.\n",
    "def cleanup_bivariate_stats(df: pd.DataFrame, sampleID: str):\n",
    "    # We need to add a column equal to sampleID.\n",
    "    df['SampleID'] = sampleID\n",
    "\n",
    "    # Pop the old index.\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Set the index as the sampleID.\n",
    "    df.set_index(['SampleID'], inplace=True)\n",
    "\n",
    "    # We need to rename the \"index\" column to pipeline.\n",
    "    df.rename(columns={'index': 'Pipeline'}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert from Genus, RA, Source, SampleID to Genus RA_x, RA_y, Source, SampleID.\n",
    "def convert_to_bivariate(root_dir: str, save_path=None, inset=False, rank=None) -> pd.DataFrame:\n",
    "    if rank is None:\n",
    "        raise Exception(\"Rank cannot be None.\")\n",
    "\n",
    "    df = fully_combined(root_dir, rank=rank)\n",
    "\n",
    "    combined_stats = pd.DataFrame()\n",
    "    for sample, sample_df in df.groupby('SampleID'):\n",
    "        bivariate_df = pd.DataFrame()\n",
    "        # Get the expected dataframe.\n",
    "        expected = sample_df[sample_df['Source'] == 'Expected']\n",
    "\n",
    "        # Get the dirname of the root directory.\n",
    "        dirname = root_dir.split('/')[-1]\n",
    "        # print(dirname)\n",
    "\n",
    "        # Get the experimental dataframe.\n",
    "        experimental = sample_df[(sample_df['Source'] != 'Expected') & (sample_df['Source'] != dirname)]\n",
    "        # display(expected)\n",
    "        # display(experimental)\n",
    "\n",
    "        # We want to join outer on the expected dataframe after grouping by source. This will show the missing values from the expected.\n",
    "        for source, source_df in experimental.groupby('Source'):\n",
    "            # Merge the expected and experimental dataframes.\n",
    "            merged = pd.merge(expected, source_df, on=\"TAX_ID\", how='outer', suffixes=('_expected', '_observed'))\n",
    "            merged = fix_outer_join_df(df=merged, source=source)\n",
    "            # merged['RA_observed'].fillna(0, inplace=True)\n",
    "            # merged['Source_observed'].fillna(source, inplace=True)\n",
    "            # merged['SampleID'] = sample\n",
    "            # display(merged)\n",
    "            bivariate_df = pd.concat([bivariate_df, merged], axis=0)\n",
    "\n",
    "        # Add the merged dataframe to the bivariate dataframe.\n",
    "\n",
    "        title = f\"Bivariate Linear Regression for Sample {sample} in Experiment {dirname}\"\n",
    "\n",
    "        # bivariate_df = bivariate_df.sort_values(by='RA_expected', ascending=False).head(30)\n",
    "        if save_path is not None:\n",
    "            stats_df = linear_plot(bivariate_df, title, sample, hue_category=\"Source_observed\", save_path=os.path.join(root_dir, f\"{sample}_linear_{rank}_all.png\"), inset=inset)\n",
    "            stats_df = cleanup_bivariate_stats(stats_df, sample)\n",
    "\n",
    "            combined_stats = pd.concat([combined_stats, stats_df], axis=0)\n",
    "        else:\n",
    "            stats_df = linear_plot(bivariate_df, title, sample, hue_category=\"Source_observed\", save_path=None)\n",
    "            stats_df = cleanup_bivariate_stats(stats_df, sample)\n",
    "\n",
    "            combined_stats = pd.concat([combined_stats, stats_df], axis=0)\n",
    "\n",
    "    return combined_stats\n",
    "# bivariate_df = convert_to_bivariate(fully_combined())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Samples (Replicates) with One Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used for multiple samples from the same pipeline against the same expected.\n",
    "def plot_many_versus_expected(root_dir, output_dir, in_df, rank):\n",
    "    expected = in_df[in_df['Source'] == 'Expected']\n",
    "    experimental = in_df[in_df['Source'] != 'Expected']\n",
    "\n",
    "    dirname = root_dir.split('/')[-1]\n",
    "    for pipeline, df in experimental.groupby('Source'):\n",
    "        print(pipeline)\n",
    "        if pipeline == 'Expected':\n",
    "            raise Exception(\"Pipeline should not be Expected.\")\n",
    "        \n",
    "        if pipeline != dirname:\n",
    "            fig = plt.figure(figsize=(15, 12))\n",
    "\n",
    "            df = df.where(df['RA'] > 0.001).dropna()\n",
    "\n",
    "            # display(df.head())\n",
    "\n",
    "            # Add the expected dataframe to the combined dataframe.\n",
    "            merged = pd.concat([expected, df], axis=0)\n",
    "\n",
    "            # Sample names change, so we can just use the same set of colors rather than having to change them.\n",
    "            ax = sns.barplot(x=merged.index, y='RA', hue=\"SampleID\", data=merged, errorbar=None, log=True, palette=cb_palette)\n",
    "            ticks = [0.001, 0.01, 0.10]\n",
    "            ax.set_yticks(ticks)\n",
    "            ax.set_yticklabels(ticks)\n",
    "            # ax.bar_label(ax.containers[0], fmt='%.2e', label_type='center')\n",
    "            # ax.bar_label(ax.containers[1], fmt='%.2e', label_type='edge')\n",
    "\n",
    "            ax.set_xticklabels(fix_x_labels(ax=ax, df=merged, rank=rank), rotation=45, horizontalalignment='right')\n",
    "            # ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "            title = f\"Expected vs. Observed Relative Abundance for {rank} using {pipeline} in Experiment {dirname}\"\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel(rank)\n",
    "            ax.set_ylabel('Relative Abundance')\n",
    "\n",
    "            pdf_output.savefig(fig, bbox_inches='tight', dpi=300)\n",
    "            plt.close(fig)\n",
    "            # plt.savefig(os.path.join(output_dir, f\"{pipeline}\", f\"{pipeline}_bars.png\"), dpi=300, bbox_inches='tight')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# plot_many_versus_expected(root_dir, fully_combined(), \"genus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot the expected vs. observed for each sample in each pipeline.\n",
    "# There is only one expected value for each sample since they are replicates.\n",
    "# This will be a bivariate plot.\n",
    "def plot_many_versus_expected_bivariate(root_dir, observed_df, expected_df, rank, inset) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function will plot the expected vs. observed for each sample in each pipeline. \n",
    "    There is only one expected value for each sample since they are replicates. \n",
    "    This will be a bivariate plot that will include MAE, r^2 and Aitchison distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_dir : str\n",
    "        The root directory of the pipeline.\n",
    "    observed_df : pd.DataFrame\n",
    "        The observed dataframe.\n",
    "    expected_df : pd.DataFrame\n",
    "        The expected dataframe.\n",
    "    rank : str\n",
    "        The taxonomic rank.\n",
    "    inset : bool\n",
    "        Whether or not to include an inset plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A dataframe containing the statistics for each sample.\n",
    "    \"\"\"\n",
    "    # First, we need to make a df of observed vs. expected for each sample.\n",
    "    combined_stats = pd.DataFrame()\n",
    "    for pipeline, pipeline_df in observed_df.groupby(\"Source\"):\n",
    "            # Plotting expected vs expected is useless.\n",
    "            if pipeline == \"tourlousse\" or pipeline == \"Expected\":\n",
    "                continue\n",
    "\n",
    "            # We are going to merge outer so that we can see which organisms are missing from the expected or are not supposed to be there. \n",
    "            merged = pd.merge(expected_df.copy(), pipeline_df, on='TAX_ID', how='outer', suffixes=('_expected', '_observed'))\n",
    "            merged = fix_outer_join_df(merged, pipeline)\n",
    "\n",
    "            # merged.to_csv(\"bivariate_debug.csv\", mode='a')\n",
    "\n",
    "            save_path = os.path.join(root_dir, pipeline, f\"{pipeline}_bivariate_{rank}_all_samples.png\")\n",
    "            # merged.to_csv(os.path.join(root_dir, pipeline, f\"{pipeline}_bivariate_{rank}_all_samples.csv\"))\n",
    "\n",
    "            exp_name = os.path.basename(root_dir)\n",
    "\n",
    "            # Add amos to the mixed or hilo samples since they are nested.\n",
    "            if exp_name == \"mixed\" or exp_name == \"hilo\":\n",
    "                exp_name = \"Amos \" + exp_name\n",
    "\n",
    "            pipeline_stats = linear_plot(merged, f\"Expected vs. Observed Relative Abundance for {rank} using {pipeline} in Experiment {exp_name}\", pipeline, hue_category=\"SampleID_observed\", save_path=save_path, inset=inset, colors=cb_palette)\n",
    "\n",
    "            # Add pipeline column to the stats dataframe equal to the pipeline name.\n",
    "            pipeline_stats['Pipeline'] = pipeline\n",
    "\n",
    "            # Add the pipeline stats to the combined stats dataframe.\n",
    "            combined_stats = pd.concat([combined_stats, pipeline_stats], axis=0)\n",
    "\n",
    "    return combined_stats\n",
    "\n",
    "# plot_many_versus_expected_bivariate(get_relabund_files(root_dir), get_all_expected(root_dir, \"genus\"), \"genus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code here: MAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can initialize the dataclasses to hold the parameters for each pipeline.\n",
    "@dataclass\n",
    "class Pipeline:\n",
    "    root: str\n",
    "    inset: bool\n",
    "\n",
    "    def __init__(self, root: str, inset: bool):\n",
    "        self.root = root\n",
    "        self.inset = inset\n",
    "\n",
    "bmock12 = Pipeline(\"pipelines/bmock12\", False)\n",
    "camisim = Pipeline(\"pipelines/camisimGI\", True)\n",
    "tourlousse = Pipeline(\"pipelines/tourlousse\", False)\n",
    "amos_hilo = Pipeline(\"pipelines/amos/hilo\", False)\n",
    "amos_mixed = Pipeline(\"pipelines/amos/mixed\", False)\n",
    "\n",
    "# No ending slash for these directories.\n",
    "root_dirs_one_to_one = [bmock12, camisim]\n",
    "# root_dirs_one_to_one = [bmock12]\n",
    "root_dirs_one_to_many = [tourlousse, amos_hilo, amos_mixed]\n",
    "# root_dirs_one_to_many = [amos_mixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    def one_to_one():\n",
    "        for exp in root_dirs_one_to_one:\n",
    "            print(\"Experiment: \", exp.root)\n",
    "            plot_by_sample(root=exp.root, output_dir=exp.root, hue_category=\"Source\", taxonomic_rank=\"Genus\")\n",
    "            plot_by_sample(root=exp.root, output_dir=exp.root, hue_category=\"Source\", taxonomic_rank=\"Species\")\n",
    "            final_stats = convert_to_bivariate(exp.root, save_path=exp.root, inset=exp.inset, rank=\"Genus\")\n",
    "            final_stats = convert_to_bivariate(exp.root, save_path=exp.root, inset=exp.inset, rank=\"Species\")\n",
    "            final_stats.to_csv(os.path.join(exp.root, \"all_stats_replicates.csv\"), index_label=\"SampleID\")\n",
    "\n",
    "    def many_to_one():\n",
    "        for exp in root_dirs_one_to_many:\n",
    "            print(\"Experiment: \", exp.root)\n",
    "            plot_many_versus_expected(exp.root, exp.root, fully_combined(exp.root, rank=\"genus\"), \"genus\")\n",
    "            plot_many_versus_expected(exp.root, exp.root, fully_combined(exp.root, rank=\"species\"), \"species\")\n",
    "            final_stats = plot_many_versus_expected_bivariate(exp.root, fully_combined(exp.root, rank=\"genus\"), get_all_expected(exp.root, \"genus\"), \"genus\", inset=exp.inset)\n",
    "            final_stats = plot_many_versus_expected_bivariate(exp.root, fully_combined(exp.root, rank=\"species\"), get_all_expected(exp.root, \"species\"), \"species\", inset=exp.inset)\n",
    "            final_stats.to_csv(os.path.join(exp.root, \"all_stats_replicates.csv\"), index_label=\"SampleID\")\n",
    "\n",
    "    one_to_one()\n",
    "    many_to_one()\n",
    "    pdf_output.close()\n",
    "    \n",
    "main()\n",
    "\n",
    "# fc = fully_combined(\"pipelines/bmock12/\")\n",
    "# display(fc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.pipeline_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac10c2973d938bf4f101ae2299756abbb7e00dac649f0769819439ff384650d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
